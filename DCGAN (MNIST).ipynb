{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 0. DCGAN","metadata":{}},{"cell_type":"markdown","source":"### Reference\n- https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/dcgan/dcgan.py\n- paper : https://arxiv.org/abs/1511.06434","metadata":{}},{"cell_type":"markdown","source":"# 1. Library Import","metadata":{}},{"cell_type":"code","source":"!pip install easydict","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting easydict\n  Downloading easydict-1.9.tar.gz (6.4 kB)\nBuilding wheels for collected packages: easydict\n  Building wheel for easydict (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for easydict: filename=easydict-1.9-py3-none-any.whl size=6350 sha256=468b2bd92eb72ba0c89df5ba93becf0c665b058e9c66e52dd3842ae4566415ab\n  Stored in directory: /root/.cache/pip/wheels/88/96/68/c2be18e7406804be2e593e1c37845f2dd20ac2ce1381ce40b0\nSuccessfully built easydict\nInstalling collected packages: easydict\nSuccessfully installed easydict-1.9\n","output_type":"stream"}]},{"cell_type":"code","source":"# import argparse\nimport easydict\nimport os\nimport numpy as np\nimport math\n\nimport torchvision.transforms as transforms\nfrom torchvision.utils import save_image\n\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torch.autograd import Variable\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# make images folder\nos.makedirs('images', exist_ok = True)","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# 2. Parameter Setting","metadata":{}},{"cell_type":"code","source":"opt = easydict.EasyDict({\"n_epochs\" : 10, \"batch_size\" : 64,\n                         \"lr\" : 0.0002, \"b1\" : 0.5, \"b2\" : 0.999,\n                         \"n_cpu\" : 8, \"latent_dim\" : 100,\n                         \"img_size\" : 32, \"channels\" : 1,\n                         \"sample_interval\" : 400})","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(opt)","metadata":{"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"{'n_epochs': 10, 'batch_size': 64, 'lr': 0.0002, 'b1': 0.5, 'b2': 0.999, 'n_cpu': 8, 'latent_dim': 100, 'img_size': 32, 'channels': 1, 'sample_interval': 400}\n","output_type":"stream"}]},{"cell_type":"code","source":"cuda = True if torch.cuda.is_available() else False","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(cuda)","metadata":{"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 3. Model","metadata":{}},{"cell_type":"markdown","source":"#### 3.1 Weights Init","metadata":{}},{"cell_type":"code","source":"def weights_init_normal(m):\n    classname = m.__class__.__name__\n    if classname.find(\"Conv\") != -1:\n        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find(\"BatchNorm2d\") != -1:\n        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n        torch.nn.init.constant_(m.bias.data, 0.0)","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"gg = Generator()","metadata":{"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"gg.apply(weights_init_normal)","metadata":{"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Generator(\n  (l1): Sequential(\n    (0): Linear(in_features=100, out_features=8192, bias=True)\n  )\n  (conv_blocks): Sequential(\n    (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (1): Upsample(scale_factor=2.0, mode=nearest)\n    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n    (5): Upsample(scale_factor=2.0, mode=nearest)\n    (6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n    (9): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (10): Tanh()\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"gg","metadata":{"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"Generator(\n  (l1): Sequential(\n    (0): Linear(in_features=100, out_features=8192, bias=True)\n  )\n  (conv_blocks): Sequential(\n    (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (1): Upsample(scale_factor=2.0, mode=nearest)\n    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n    (5): Upsample(scale_factor=2.0, mode=nearest)\n    (6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n    (9): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (10): Tanh()\n  )\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"#### 3.2 Generator Model","metadata":{}},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        \n        # 32 // 4 = 8\n        # 128 * 8 ** 2 = 8192\n        self.init_size = opt.img_size // 4\n        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim, 128 * self.init_size ** 2))\n        \n        self.conv_blocks = nn.Sequential(nn.BatchNorm2d(128),\n                                         nn.Upsample(scale_factor = 2),\n                                         nn.Conv2d(128, 128, 3, stride = 1, padding = 1),\n                                         nn.BatchNorm2d(128, 0.8),\n                                         nn.LeakyReLU(0.2, inplace = True),\n                                         nn.Upsample(scale_factor = 2),\n                                         nn.Conv2d(128, 64, 3, stride = 1, padding = 1),\n                                         nn.BatchNorm2d(64, 0.8),\n                                         nn.LeakyReLU(0.2, inplace = True),\n                                         nn.Conv2d(64, opt.channels, 3, stride = 1, padding = 1),\n                                         nn.Tanh()\n                                        )\n        \n    def forward(self, z):\n        out = self.l1(z)\n        # batch size * 128 channel * 8 * 8\n        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n        img = self.conv_blocks(out)\n        return img","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"#### 3.3 Discriminator","metadata":{}},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        \n        def discriminator_block(in_filters, out_filters, bn = True):\n            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1),\n                     nn.LeakyReLU(0.2, inplace = True),\n                     nn.Dropout2d(0.25)]\n            if bn:\n                block.append(nn.BatchNorm2d(out_filters, 0.8))\n            return block\n        \n        self.model = nn.Sequential(*discriminator_block(opt.channels, 16, bn = False),\n                                   *discriminator_block(16, 32),\n                                   *discriminator_block(32, 64),\n                                   *discriminator_block(64,128)\n                                  )\n        \n        # The height and width of downsampled image\n        ds_size = opt.img_size // 2 ** 4\n        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1),\n                                       nn.Sigmoid()\n                                      )\n        \n    def forward(self, img):\n        out = self.model(img)\n        out = out.view(out.shape[0], -1)\n        validity = self.adv_layer(out)\n        return validity","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"#### 3.4 Loss Function","metadata":{}},{"cell_type":"code","source":"adversarial_loss = torch.nn.BCELoss()","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# 4. Data Loader and Model Training","metadata":{}},{"cell_type":"code","source":"# Initialize generator and discriminator\ngenerator = Generator()\ndiscriminator = Discriminator()","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"if cuda:\n    generator.cuda()\n    discriminator.cuda()\n    adversarial_loss.cuda()","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Initialize weights\ngenerator.apply(weights_init_normal)\ndiscriminator.apply(weights_init_normal)","metadata":{"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"Discriminator(\n  (model): Sequential(\n    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n    (2): Dropout2d(p=0.25, inplace=False)\n    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n    (5): Dropout2d(p=0.25, inplace=False)\n    (6): BatchNorm2d(32, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n    (9): Dropout2d(p=0.25, inplace=False)\n    (10): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n    (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (12): LeakyReLU(negative_slope=0.2, inplace=True)\n    (13): Dropout2d(p=0.25, inplace=False)\n    (14): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (adv_layer): Sequential(\n    (0): Linear(in_features=512, out_features=1, bias=True)\n    (1): Sigmoid()\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n!tar -zxvf MNIST.tar.gz","metadata":{"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"--2021-04-24 12:07:34--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\nResolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\nConnecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n--2021-04-24 12:07:34--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\nConnecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: unspecified [application/x-gzip]\nSaving to: ‘MNIST.tar.gz’\n\nMNIST.tar.gz            [           <=>      ]  33.20M  15.0MB/s    in 2.2s    \n\n2021-04-24 12:07:36 (15.0 MB/s) - ‘MNIST.tar.gz’ saved [34813078]\n\nMNIST/\nMNIST/raw/\nMNIST/raw/train-labels-idx1-ubyte\nMNIST/raw/t10k-labels-idx1-ubyte.gz\nMNIST/raw/t10k-labels-idx1-ubyte\nMNIST/raw/t10k-images-idx3-ubyte.gz\nMNIST/raw/train-images-idx3-ubyte\nMNIST/raw/train-labels-idx1-ubyte.gz\nMNIST/raw/t10k-images-idx3-ubyte\nMNIST/raw/train-images-idx3-ubyte.gz\nMNIST/processed/\nMNIST/processed/training.pt\nMNIST/processed/test.pt\n","output_type":"stream"}]},{"cell_type":"code","source":"# Condigure data loader\nos.makedirs(\"./\", exist_ok = True)\ndataloader = torch.utils.data.DataLoader(\n                datasets.MNIST(\n                    \"./\",\n                    train = True,\n                    download = True,\n                    transform = transforms.Compose(\n                        [transforms.Resize(opt.img_size), transforms.ToTensor(),\n                         transforms.Normalize([0.5], [0.5])]\n                    )\n                ),\n                batch_size = opt.batch_size,\n                shuffle = True\n            )","metadata":{"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Optimizers\noptimizer_G = torch.optim.Adam(generator.parameters(), lr = opt.lr, betas = (opt.b1, opt.b2))\noptimizer_D = torch.optim.Adam(discriminator.parameters(), lr = opt.lr, betas = (opt.b1, opt.b2))","metadata":{"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor","metadata":{"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Training\nfor epoch in range(opt.n_epochs):\n    for i, (imgs, _) in enumerate(dataloader):\n        # Adversarial ground truths\n        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad = False)\n        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad = False)\n        \n        # Configure input\n        real_imgs = Variable(imgs.type(Tensor))\n        \n        ###################\n        # Train Generator #\n        ###################\n        \n        optimizer_G.zero_grad()\n        \n        # Sample noise as generator input\n        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n        \n        # Generator a batch of images\n        gen_imgs = generator(z)\n        \n        # Loss measures generator's ability to fool the discriminator\n        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n        \n        g_loss.backward()\n        optimizer_G.step()\n        \n        \n        #######################\n        # Train Discriminator #\n        #######################\n        \n        optimizer_D.zero_grad()\n        \n        # Measure discriminator's aility to classify real from generated samples\n        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n        d_loss = (real_loss + fake_loss) / 2\n        \n        d_loss.backward()\n        optimizer_D.step()\n        \n        if i % 20 == 0:\n            print(\"[Epoch %d / %d] [Batch %d / %d] [D loss: %f] [G loss: %f]\"\n                  % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n                 )\n        \n        batches_done = epoch * len(dataloader) + i\n        if batches_done % opt.sample_interval == 0:\n            save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow = 5, normalize = True)","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"[Epoch 0 / 10] [Batch 0 / 938] [D loss: 0.693363] [G loss: 0.672970]\n[Epoch 0 / 10] [Batch 20 / 938] [D loss: 0.691747] [G loss: 0.675183]\n[Epoch 0 / 10] [Batch 40 / 938] [D loss: 0.683623] [G loss: 0.688669]\n[Epoch 0 / 10] [Batch 60 / 938] [D loss: 0.686531] [G loss: 0.671084]\n[Epoch 0 / 10] [Batch 80 / 938] [D loss: 0.689837] [G loss: 0.671968]\n[Epoch 0 / 10] [Batch 100 / 938] [D loss: 0.693792] [G loss: 0.705220]\n[Epoch 0 / 10] [Batch 120 / 938] [D loss: 0.696985] [G loss: 0.702821]\n[Epoch 0 / 10] [Batch 140 / 938] [D loss: 0.694378] [G loss: 0.684572]\n[Epoch 0 / 10] [Batch 160 / 938] [D loss: 0.690753] [G loss: 0.727053]\n[Epoch 0 / 10] [Batch 180 / 938] [D loss: 0.686377] [G loss: 0.691130]\n[Epoch 0 / 10] [Batch 200 / 938] [D loss: 0.692442] [G loss: 0.713231]\n[Epoch 0 / 10] [Batch 220 / 938] [D loss: 0.695171] [G loss: 0.696384]\n[Epoch 0 / 10] [Batch 240 / 938] [D loss: 0.694592] [G loss: 0.687491]\n[Epoch 0 / 10] [Batch 260 / 938] [D loss: 0.696945] [G loss: 0.704127]\n[Epoch 0 / 10] [Batch 280 / 938] [D loss: 0.692146] [G loss: 0.693506]\n[Epoch 0 / 10] [Batch 300 / 938] [D loss: 0.692980] [G loss: 0.695240]\n[Epoch 0 / 10] [Batch 320 / 938] [D loss: 0.695702] [G loss: 0.692911]\n[Epoch 0 / 10] [Batch 340 / 938] [D loss: 0.692804] [G loss: 0.693109]\n[Epoch 0 / 10] [Batch 360 / 938] [D loss: 0.696111] [G loss: 0.683614]\n[Epoch 0 / 10] [Batch 380 / 938] [D loss: 0.688875] [G loss: 0.684205]\n[Epoch 0 / 10] [Batch 400 / 938] [D loss: 0.696849] [G loss: 0.685315]\n[Epoch 0 / 10] [Batch 420 / 938] [D loss: 0.691564] [G loss: 0.695307]\n[Epoch 0 / 10] [Batch 440 / 938] [D loss: 0.690599] [G loss: 0.711997]\n[Epoch 0 / 10] [Batch 460 / 938] [D loss: 0.696396] [G loss: 0.671354]\n[Epoch 0 / 10] [Batch 480 / 938] [D loss: 0.698642] [G loss: 0.685214]\n[Epoch 0 / 10] [Batch 500 / 938] [D loss: 0.689646] [G loss: 0.701390]\n[Epoch 0 / 10] [Batch 520 / 938] [D loss: 0.692167] [G loss: 0.687602]\n[Epoch 0 / 10] [Batch 540 / 938] [D loss: 0.694842] [G loss: 0.692143]\n[Epoch 0 / 10] [Batch 560 / 938] [D loss: 0.685706] [G loss: 0.696622]\n[Epoch 0 / 10] [Batch 580 / 938] [D loss: 0.688185] [G loss: 0.689880]\n[Epoch 0 / 10] [Batch 600 / 938] [D loss: 0.694421] [G loss: 0.725043]\n[Epoch 0 / 10] [Batch 620 / 938] [D loss: 0.694640] [G loss: 0.705660]\n[Epoch 0 / 10] [Batch 640 / 938] [D loss: 0.682549] [G loss: 0.695990]\n[Epoch 0 / 10] [Batch 660 / 938] [D loss: 0.693700] [G loss: 0.709352]\n[Epoch 0 / 10] [Batch 680 / 938] [D loss: 0.695785] [G loss: 0.698263]\n[Epoch 0 / 10] [Batch 700 / 938] [D loss: 0.693158] [G loss: 0.699170]\n[Epoch 0 / 10] [Batch 720 / 938] [D loss: 0.685757] [G loss: 0.711018]\n[Epoch 0 / 10] [Batch 740 / 938] [D loss: 0.710780] [G loss: 0.677256]\n[Epoch 0 / 10] [Batch 760 / 938] [D loss: 0.707262] [G loss: 0.682270]\n[Epoch 0 / 10] [Batch 780 / 938] [D loss: 0.692967] [G loss: 0.710661]\n[Epoch 0 / 10] [Batch 800 / 938] [D loss: 0.696220] [G loss: 0.690525]\n[Epoch 0 / 10] [Batch 820 / 938] [D loss: 0.701343] [G loss: 0.670989]\n[Epoch 0 / 10] [Batch 840 / 938] [D loss: 0.691173] [G loss: 0.667117]\n[Epoch 0 / 10] [Batch 860 / 938] [D loss: 0.705235] [G loss: 0.648495]\n[Epoch 0 / 10] [Batch 880 / 938] [D loss: 0.697495] [G loss: 0.676219]\n[Epoch 0 / 10] [Batch 900 / 938] [D loss: 0.686962] [G loss: 0.701113]\n[Epoch 0 / 10] [Batch 920 / 938] [D loss: 0.691220] [G loss: 0.719167]\n[Epoch 1 / 10] [Batch 0 / 938] [D loss: 0.699525] [G loss: 0.703458]\n[Epoch 1 / 10] [Batch 20 / 938] [D loss: 0.676279] [G loss: 0.685935]\n[Epoch 1 / 10] [Batch 40 / 938] [D loss: 0.691265] [G loss: 0.707050]\n[Epoch 1 / 10] [Batch 60 / 938] [D loss: 0.677173] [G loss: 0.691603]\n[Epoch 1 / 10] [Batch 80 / 938] [D loss: 0.672668] [G loss: 0.677785]\n[Epoch 1 / 10] [Batch 100 / 938] [D loss: 0.686392] [G loss: 0.730185]\n[Epoch 1 / 10] [Batch 120 / 938] [D loss: 0.673771] [G loss: 0.706613]\n[Epoch 1 / 10] [Batch 140 / 938] [D loss: 0.694922] [G loss: 0.773048]\n[Epoch 1 / 10] [Batch 160 / 938] [D loss: 0.695661] [G loss: 0.641249]\n[Epoch 1 / 10] [Batch 180 / 938] [D loss: 0.688886] [G loss: 0.639287]\n[Epoch 1 / 10] [Batch 200 / 938] [D loss: 0.668314] [G loss: 0.764994]\n[Epoch 1 / 10] [Batch 220 / 938] [D loss: 0.668062] [G loss: 0.755166]\n[Epoch 1 / 10] [Batch 240 / 938] [D loss: 0.655755] [G loss: 0.751454]\n[Epoch 1 / 10] [Batch 260 / 938] [D loss: 0.679982] [G loss: 0.732713]\n[Epoch 1 / 10] [Batch 280 / 938] [D loss: 0.654642] [G loss: 0.728516]\n[Epoch 1 / 10] [Batch 300 / 938] [D loss: 0.650039] [G loss: 0.723916]\n[Epoch 1 / 10] [Batch 320 / 938] [D loss: 0.648609] [G loss: 0.816856]\n[Epoch 1 / 10] [Batch 340 / 938] [D loss: 0.690608] [G loss: 0.727572]\n[Epoch 1 / 10] [Batch 360 / 938] [D loss: 0.667615] [G loss: 0.770055]\n[Epoch 1 / 10] [Batch 380 / 938] [D loss: 0.659868] [G loss: 0.725785]\n[Epoch 1 / 10] [Batch 400 / 938] [D loss: 0.638543] [G loss: 0.767651]\n[Epoch 1 / 10] [Batch 420 / 938] [D loss: 0.670855] [G loss: 0.834201]\n[Epoch 1 / 10] [Batch 440 / 938] [D loss: 0.640555] [G loss: 0.817011]\n[Epoch 1 / 10] [Batch 460 / 938] [D loss: 0.716258] [G loss: 0.716532]\n[Epoch 1 / 10] [Batch 480 / 938] [D loss: 0.692677] [G loss: 0.706489]\n[Epoch 1 / 10] [Batch 500 / 938] [D loss: 0.636809] [G loss: 0.842387]\n[Epoch 1 / 10] [Batch 520 / 938] [D loss: 0.656596] [G loss: 0.738126]\n[Epoch 1 / 10] [Batch 540 / 938] [D loss: 0.697482] [G loss: 0.804926]\n[Epoch 1 / 10] [Batch 560 / 938] [D loss: 0.689993] [G loss: 0.800534]\n[Epoch 1 / 10] [Batch 580 / 938] [D loss: 0.650358] [G loss: 0.683653]\n[Epoch 1 / 10] [Batch 600 / 938] [D loss: 0.685646] [G loss: 0.839443]\n[Epoch 1 / 10] [Batch 620 / 938] [D loss: 0.600071] [G loss: 0.709979]\n[Epoch 1 / 10] [Batch 640 / 938] [D loss: 0.666628] [G loss: 0.780423]\n[Epoch 1 / 10] [Batch 660 / 938] [D loss: 0.608323] [G loss: 0.913015]\n[Epoch 1 / 10] [Batch 680 / 938] [D loss: 0.665649] [G loss: 0.782240]\n[Epoch 1 / 10] [Batch 700 / 938] [D loss: 0.660170] [G loss: 0.919345]\n[Epoch 1 / 10] [Batch 720 / 938] [D loss: 0.626456] [G loss: 0.743723]\n[Epoch 1 / 10] [Batch 740 / 938] [D loss: 0.668502] [G loss: 0.766067]\n[Epoch 1 / 10] [Batch 760 / 938] [D loss: 0.698486] [G loss: 0.831291]\n[Epoch 1 / 10] [Batch 780 / 938] [D loss: 0.635772] [G loss: 0.620766]\n[Epoch 1 / 10] [Batch 800 / 938] [D loss: 0.763532] [G loss: 0.758089]\n[Epoch 1 / 10] [Batch 820 / 938] [D loss: 0.635781] [G loss: 0.662086]\n[Epoch 1 / 10] [Batch 840 / 938] [D loss: 0.643394] [G loss: 0.756334]\n[Epoch 1 / 10] [Batch 860 / 938] [D loss: 0.657301] [G loss: 0.703178]\n[Epoch 1 / 10] [Batch 880 / 938] [D loss: 0.621789] [G loss: 0.691277]\n[Epoch 1 / 10] [Batch 900 / 938] [D loss: 0.683990] [G loss: 0.844243]\n[Epoch 1 / 10] [Batch 920 / 938] [D loss: 0.695695] [G loss: 0.795509]\n[Epoch 2 / 10] [Batch 0 / 938] [D loss: 0.672491] [G loss: 0.680982]\n[Epoch 2 / 10] [Batch 20 / 938] [D loss: 0.666762] [G loss: 0.789133]\n[Epoch 2 / 10] [Batch 40 / 938] [D loss: 0.654651] [G loss: 0.751329]\n[Epoch 2 / 10] [Batch 60 / 938] [D loss: 0.683725] [G loss: 0.726850]\n[Epoch 2 / 10] [Batch 80 / 938] [D loss: 0.651888] [G loss: 0.700434]\n[Epoch 2 / 10] [Batch 100 / 938] [D loss: 0.660832] [G loss: 0.884185]\n[Epoch 2 / 10] [Batch 120 / 938] [D loss: 0.643676] [G loss: 0.762024]\n[Epoch 2 / 10] [Batch 140 / 938] [D loss: 0.632419] [G loss: 0.843351]\n[Epoch 2 / 10] [Batch 160 / 938] [D loss: 0.578622] [G loss: 0.848131]\n[Epoch 2 / 10] [Batch 180 / 938] [D loss: 0.768720] [G loss: 0.767639]\n[Epoch 2 / 10] [Batch 200 / 938] [D loss: 0.676371] [G loss: 0.800983]\n[Epoch 2 / 10] [Batch 220 / 938] [D loss: 0.605004] [G loss: 0.808476]\n[Epoch 2 / 10] [Batch 240 / 938] [D loss: 0.618962] [G loss: 0.708506]\n[Epoch 2 / 10] [Batch 260 / 938] [D loss: 0.680604] [G loss: 0.934752]\n[Epoch 2 / 10] [Batch 280 / 938] [D loss: 0.660290] [G loss: 0.835903]\n[Epoch 2 / 10] [Batch 300 / 938] [D loss: 0.687734] [G loss: 0.814848]\n[Epoch 2 / 10] [Batch 320 / 938] [D loss: 0.598058] [G loss: 0.839334]\n[Epoch 2 / 10] [Batch 340 / 938] [D loss: 0.587097] [G loss: 0.712548]\n[Epoch 2 / 10] [Batch 360 / 938] [D loss: 0.669176] [G loss: 0.814834]\n[Epoch 2 / 10] [Batch 380 / 938] [D loss: 0.732321] [G loss: 0.898480]\n[Epoch 2 / 10] [Batch 400 / 938] [D loss: 0.639689] [G loss: 0.855721]\n[Epoch 2 / 10] [Batch 420 / 938] [D loss: 0.599354] [G loss: 0.854156]\n[Epoch 2 / 10] [Batch 440 / 938] [D loss: 0.635967] [G loss: 0.776107]\n[Epoch 2 / 10] [Batch 460 / 938] [D loss: 0.694640] [G loss: 0.802602]\n[Epoch 2 / 10] [Batch 480 / 938] [D loss: 0.727455] [G loss: 0.557204]\n[Epoch 2 / 10] [Batch 500 / 938] [D loss: 0.588784] [G loss: 0.725194]\n[Epoch 2 / 10] [Batch 520 / 938] [D loss: 0.644848] [G loss: 0.985197]\n[Epoch 2 / 10] [Batch 540 / 938] [D loss: 0.680371] [G loss: 0.740182]\n[Epoch 2 / 10] [Batch 560 / 938] [D loss: 0.648343] [G loss: 0.845319]\n[Epoch 2 / 10] [Batch 580 / 938] [D loss: 0.657513] [G loss: 0.684984]\n[Epoch 2 / 10] [Batch 600 / 938] [D loss: 0.679100] [G loss: 0.826126]\n[Epoch 2 / 10] [Batch 620 / 938] [D loss: 0.719518] [G loss: 0.830287]\n[Epoch 2 / 10] [Batch 640 / 938] [D loss: 0.690410] [G loss: 0.670400]\n[Epoch 2 / 10] [Batch 660 / 938] [D loss: 0.685944] [G loss: 0.941258]\n[Epoch 2 / 10] [Batch 680 / 938] [D loss: 0.687676] [G loss: 0.764039]\n[Epoch 2 / 10] [Batch 700 / 938] [D loss: 0.525326] [G loss: 0.946341]\n[Epoch 2 / 10] [Batch 720 / 938] [D loss: 0.645353] [G loss: 0.727988]\n[Epoch 2 / 10] [Batch 740 / 938] [D loss: 0.649444] [G loss: 0.660589]\n[Epoch 2 / 10] [Batch 760 / 938] [D loss: 0.637734] [G loss: 0.700083]\n[Epoch 2 / 10] [Batch 780 / 938] [D loss: 0.624891] [G loss: 0.882063]\n[Epoch 2 / 10] [Batch 800 / 938] [D loss: 0.735818] [G loss: 0.726938]\n[Epoch 2 / 10] [Batch 820 / 938] [D loss: 0.682353] [G loss: 0.857892]\n[Epoch 2 / 10] [Batch 840 / 938] [D loss: 0.630299] [G loss: 0.792528]\n[Epoch 2 / 10] [Batch 860 / 938] [D loss: 0.691653] [G loss: 0.990070]\n[Epoch 2 / 10] [Batch 880 / 938] [D loss: 0.725327] [G loss: 0.844346]\n[Epoch 2 / 10] [Batch 900 / 938] [D loss: 0.725631] [G loss: 0.793402]\n[Epoch 2 / 10] [Batch 920 / 938] [D loss: 0.657859] [G loss: 0.934966]\n[Epoch 3 / 10] [Batch 0 / 938] [D loss: 0.685571] [G loss: 0.829587]\n[Epoch 3 / 10] [Batch 20 / 938] [D loss: 0.605767] [G loss: 0.727764]\n[Epoch 3 / 10] [Batch 40 / 938] [D loss: 0.624201] [G loss: 0.961907]\n[Epoch 3 / 10] [Batch 60 / 938] [D loss: 0.615888] [G loss: 0.935375]\n[Epoch 3 / 10] [Batch 80 / 938] [D loss: 0.698110] [G loss: 0.895395]\n[Epoch 3 / 10] [Batch 100 / 938] [D loss: 0.689371] [G loss: 0.782944]\n[Epoch 3 / 10] [Batch 120 / 938] [D loss: 0.578976] [G loss: 0.780359]\n[Epoch 3 / 10] [Batch 140 / 938] [D loss: 0.694490] [G loss: 0.772662]\n[Epoch 3 / 10] [Batch 160 / 938] [D loss: 0.638248] [G loss: 0.791193]\n[Epoch 3 / 10] [Batch 180 / 938] [D loss: 0.606870] [G loss: 0.799781]\n[Epoch 3 / 10] [Batch 200 / 938] [D loss: 0.638979] [G loss: 0.635532]\n[Epoch 3 / 10] [Batch 220 / 938] [D loss: 0.687564] [G loss: 0.660940]\n[Epoch 3 / 10] [Batch 240 / 938] [D loss: 0.572503] [G loss: 0.781367]\n[Epoch 3 / 10] [Batch 260 / 938] [D loss: 0.583741] [G loss: 0.916226]\n[Epoch 3 / 10] [Batch 280 / 938] [D loss: 0.789002] [G loss: 0.743597]\n[Epoch 3 / 10] [Batch 300 / 938] [D loss: 0.590998] [G loss: 0.926328]\n[Epoch 3 / 10] [Batch 320 / 938] [D loss: 0.574416] [G loss: 0.762223]\n[Epoch 3 / 10] [Batch 340 / 938] [D loss: 0.703472] [G loss: 0.734806]\n[Epoch 3 / 10] [Batch 360 / 938] [D loss: 0.608569] [G loss: 0.785162]\n[Epoch 3 / 10] [Batch 380 / 938] [D loss: 0.594342] [G loss: 0.721410]\n[Epoch 3 / 10] [Batch 400 / 938] [D loss: 0.605479] [G loss: 0.697997]\n[Epoch 3 / 10] [Batch 420 / 938] [D loss: 0.629552] [G loss: 0.770051]\n[Epoch 3 / 10] [Batch 440 / 938] [D loss: 0.680718] [G loss: 0.899102]\n[Epoch 3 / 10] [Batch 460 / 938] [D loss: 0.744470] [G loss: 0.740565]\n[Epoch 3 / 10] [Batch 480 / 938] [D loss: 0.573753] [G loss: 0.798447]\n[Epoch 3 / 10] [Batch 500 / 938] [D loss: 0.649038] [G loss: 0.667827]\n[Epoch 3 / 10] [Batch 520 / 938] [D loss: 0.542712] [G loss: 0.832755]\n[Epoch 3 / 10] [Batch 540 / 938] [D loss: 0.612727] [G loss: 0.641341]\n[Epoch 3 / 10] [Batch 560 / 938] [D loss: 0.556135] [G loss: 0.991275]\n[Epoch 3 / 10] [Batch 580 / 938] [D loss: 0.621515] [G loss: 0.743879]\n[Epoch 3 / 10] [Batch 600 / 938] [D loss: 0.684062] [G loss: 0.872545]\n[Epoch 3 / 10] [Batch 620 / 938] [D loss: 0.565228] [G loss: 1.089570]\n[Epoch 3 / 10] [Batch 640 / 938] [D loss: 0.712918] [G loss: 0.838050]\n[Epoch 3 / 10] [Batch 660 / 938] [D loss: 0.567662] [G loss: 0.730966]\n[Epoch 3 / 10] [Batch 680 / 938] [D loss: 0.674821] [G loss: 0.650645]\n[Epoch 3 / 10] [Batch 700 / 938] [D loss: 0.610506] [G loss: 0.832572]\n[Epoch 3 / 10] [Batch 720 / 938] [D loss: 0.610485] [G loss: 0.931888]\n[Epoch 3 / 10] [Batch 740 / 938] [D loss: 0.647040] [G loss: 1.072295]\n[Epoch 3 / 10] [Batch 760 / 938] [D loss: 0.559504] [G loss: 0.918684]\n[Epoch 3 / 10] [Batch 780 / 938] [D loss: 0.571242] [G loss: 1.030438]\n[Epoch 3 / 10] [Batch 800 / 938] [D loss: 0.662912] [G loss: 0.842907]\n[Epoch 3 / 10] [Batch 820 / 938] [D loss: 0.615787] [G loss: 0.792973]\n[Epoch 3 / 10] [Batch 840 / 938] [D loss: 0.547234] [G loss: 0.747815]\n[Epoch 3 / 10] [Batch 860 / 938] [D loss: 0.663675] [G loss: 1.036552]\n[Epoch 3 / 10] [Batch 880 / 938] [D loss: 0.574112] [G loss: 0.976844]\n[Epoch 3 / 10] [Batch 900 / 938] [D loss: 0.624056] [G loss: 0.796509]\n[Epoch 3 / 10] [Batch 920 / 938] [D loss: 0.660631] [G loss: 0.822352]\n[Epoch 4 / 10] [Batch 0 / 938] [D loss: 0.618269] [G loss: 1.181444]\n[Epoch 4 / 10] [Batch 20 / 938] [D loss: 0.596345] [G loss: 0.748802]\n[Epoch 4 / 10] [Batch 40 / 938] [D loss: 0.644485] [G loss: 0.883384]\n[Epoch 4 / 10] [Batch 60 / 938] [D loss: 0.572318] [G loss: 1.080186]\n[Epoch 4 / 10] [Batch 80 / 938] [D loss: 0.567093] [G loss: 0.784289]\n[Epoch 4 / 10] [Batch 100 / 938] [D loss: 0.639128] [G loss: 0.939821]\n[Epoch 4 / 10] [Batch 120 / 938] [D loss: 0.590887] [G loss: 0.701693]\n[Epoch 4 / 10] [Batch 140 / 938] [D loss: 0.726623] [G loss: 0.824559]\n[Epoch 4 / 10] [Batch 160 / 938] [D loss: 0.598550] [G loss: 0.815928]\n[Epoch 4 / 10] [Batch 180 / 938] [D loss: 0.561144] [G loss: 1.081003]\n[Epoch 4 / 10] [Batch 200 / 938] [D loss: 0.591524] [G loss: 1.099815]\n[Epoch 4 / 10] [Batch 220 / 938] [D loss: 0.637857] [G loss: 0.967355]\n[Epoch 4 / 10] [Batch 240 / 938] [D loss: 0.632090] [G loss: 0.862656]\n[Epoch 4 / 10] [Batch 260 / 938] [D loss: 0.707904] [G loss: 0.744307]\n[Epoch 4 / 10] [Batch 280 / 938] [D loss: 0.598191] [G loss: 1.115775]\n[Epoch 4 / 10] [Batch 300 / 938] [D loss: 0.600497] [G loss: 0.769905]\n[Epoch 4 / 10] [Batch 320 / 938] [D loss: 0.571505] [G loss: 0.669928]\n[Epoch 4 / 10] [Batch 340 / 938] [D loss: 0.652990] [G loss: 0.802966]\n[Epoch 4 / 10] [Batch 360 / 938] [D loss: 0.557604] [G loss: 0.749658]\n[Epoch 4 / 10] [Batch 380 / 938] [D loss: 0.508780] [G loss: 0.867814]\n[Epoch 4 / 10] [Batch 400 / 938] [D loss: 0.544211] [G loss: 0.905581]\n[Epoch 4 / 10] [Batch 420 / 938] [D loss: 0.616803] [G loss: 0.978730]\n[Epoch 4 / 10] [Batch 440 / 938] [D loss: 0.647908] [G loss: 1.167422]\n[Epoch 4 / 10] [Batch 460 / 938] [D loss: 0.757829] [G loss: 1.156754]\n[Epoch 4 / 10] [Batch 480 / 938] [D loss: 0.580159] [G loss: 0.791481]\n[Epoch 4 / 10] [Batch 500 / 938] [D loss: 0.557299] [G loss: 0.737901]\n[Epoch 4 / 10] [Batch 520 / 938] [D loss: 0.746929] [G loss: 1.071040]\n[Epoch 4 / 10] [Batch 540 / 938] [D loss: 0.611218] [G loss: 1.125531]\n[Epoch 4 / 10] [Batch 560 / 938] [D loss: 0.572941] [G loss: 0.788752]\n[Epoch 4 / 10] [Batch 580 / 938] [D loss: 0.681930] [G loss: 0.750646]\n[Epoch 4 / 10] [Batch 600 / 938] [D loss: 0.607927] [G loss: 0.871264]\n[Epoch 4 / 10] [Batch 620 / 938] [D loss: 0.591927] [G loss: 0.746699]\n[Epoch 4 / 10] [Batch 640 / 938] [D loss: 0.651615] [G loss: 0.925851]\n[Epoch 4 / 10] [Batch 660 / 938] [D loss: 0.558449] [G loss: 0.979486]\n[Epoch 4 / 10] [Batch 680 / 938] [D loss: 0.647526] [G loss: 1.199445]\n[Epoch 4 / 10] [Batch 700 / 938] [D loss: 0.650714] [G loss: 0.856340]\n[Epoch 4 / 10] [Batch 720 / 938] [D loss: 0.509551] [G loss: 0.728010]\n[Epoch 4 / 10] [Batch 740 / 938] [D loss: 0.557120] [G loss: 0.815314]\n[Epoch 4 / 10] [Batch 760 / 938] [D loss: 0.698434] [G loss: 0.891203]\n[Epoch 4 / 10] [Batch 780 / 938] [D loss: 0.663635] [G loss: 0.807505]\n[Epoch 4 / 10] [Batch 800 / 938] [D loss: 0.675076] [G loss: 0.885443]\n[Epoch 4 / 10] [Batch 820 / 938] [D loss: 0.623737] [G loss: 0.816504]\n[Epoch 4 / 10] [Batch 840 / 938] [D loss: 0.608391] [G loss: 0.764955]\n[Epoch 4 / 10] [Batch 860 / 938] [D loss: 0.636538] [G loss: 0.824670]\n[Epoch 4 / 10] [Batch 880 / 938] [D loss: 0.714792] [G loss: 0.912413]\n[Epoch 4 / 10] [Batch 900 / 938] [D loss: 0.589734] [G loss: 0.686652]\n[Epoch 4 / 10] [Batch 920 / 938] [D loss: 0.566541] [G loss: 0.733319]\n[Epoch 5 / 10] [Batch 0 / 938] [D loss: 0.679295] [G loss: 0.599961]\n[Epoch 5 / 10] [Batch 20 / 938] [D loss: 0.577221] [G loss: 0.828289]\n[Epoch 5 / 10] [Batch 40 / 938] [D loss: 0.601706] [G loss: 0.707629]\n[Epoch 5 / 10] [Batch 60 / 938] [D loss: 0.682074] [G loss: 0.831500]\n[Epoch 5 / 10] [Batch 80 / 938] [D loss: 0.604500] [G loss: 1.109577]\n[Epoch 5 / 10] [Batch 100 / 938] [D loss: 0.623692] [G loss: 0.878144]\n[Epoch 5 / 10] [Batch 120 / 938] [D loss: 0.646305] [G loss: 0.796128]\n[Epoch 5 / 10] [Batch 140 / 938] [D loss: 0.677206] [G loss: 0.964283]\n[Epoch 5 / 10] [Batch 160 / 938] [D loss: 0.526335] [G loss: 0.946441]\n[Epoch 5 / 10] [Batch 180 / 938] [D loss: 0.773577] [G loss: 0.718940]\n[Epoch 5 / 10] [Batch 200 / 938] [D loss: 0.627640] [G loss: 0.825483]\n[Epoch 5 / 10] [Batch 220 / 938] [D loss: 0.708697] [G loss: 1.030446]\n[Epoch 5 / 10] [Batch 240 / 938] [D loss: 0.683611] [G loss: 0.974596]\n[Epoch 5 / 10] [Batch 260 / 938] [D loss: 0.487529] [G loss: 0.779013]\n[Epoch 5 / 10] [Batch 280 / 938] [D loss: 0.608623] [G loss: 0.919116]\n[Epoch 5 / 10] [Batch 300 / 938] [D loss: 0.676376] [G loss: 0.838297]\n[Epoch 5 / 10] [Batch 320 / 938] [D loss: 0.639191] [G loss: 0.867910]\n[Epoch 5 / 10] [Batch 340 / 938] [D loss: 0.723366] [G loss: 1.024949]\n[Epoch 5 / 10] [Batch 360 / 938] [D loss: 0.787335] [G loss: 0.691104]\n[Epoch 5 / 10] [Batch 380 / 938] [D loss: 0.629966] [G loss: 0.813472]\n[Epoch 5 / 10] [Batch 400 / 938] [D loss: 0.616013] [G loss: 1.089794]\n[Epoch 5 / 10] [Batch 420 / 938] [D loss: 0.644132] [G loss: 0.910876]\n[Epoch 5 / 10] [Batch 440 / 938] [D loss: 0.574532] [G loss: 0.903762]\n[Epoch 5 / 10] [Batch 460 / 938] [D loss: 0.608138] [G loss: 0.903217]\n[Epoch 5 / 10] [Batch 480 / 938] [D loss: 0.603755] [G loss: 0.911755]\n[Epoch 5 / 10] [Batch 500 / 938] [D loss: 0.508466] [G loss: 1.058395]\n[Epoch 5 / 10] [Batch 520 / 938] [D loss: 0.578352] [G loss: 0.762091]\n[Epoch 5 / 10] [Batch 540 / 938] [D loss: 0.608900] [G loss: 1.008061]\n[Epoch 5 / 10] [Batch 560 / 938] [D loss: 0.671703] [G loss: 0.654899]\n[Epoch 5 / 10] [Batch 580 / 938] [D loss: 0.641810] [G loss: 0.993506]\n[Epoch 5 / 10] [Batch 600 / 938] [D loss: 0.620941] [G loss: 0.770884]\n[Epoch 5 / 10] [Batch 620 / 938] [D loss: 0.578794] [G loss: 0.879622]\n[Epoch 5 / 10] [Batch 640 / 938] [D loss: 0.741604] [G loss: 0.968205]\n[Epoch 5 / 10] [Batch 660 / 938] [D loss: 0.658019] [G loss: 0.850506]\n[Epoch 5 / 10] [Batch 680 / 938] [D loss: 0.589682] [G loss: 0.932264]\n[Epoch 5 / 10] [Batch 700 / 938] [D loss: 0.595242] [G loss: 0.648929]\n[Epoch 5 / 10] [Batch 720 / 938] [D loss: 0.549016] [G loss: 0.674031]\n[Epoch 5 / 10] [Batch 740 / 938] [D loss: 0.542435] [G loss: 0.821328]\n[Epoch 5 / 10] [Batch 760 / 938] [D loss: 0.594269] [G loss: 0.526557]\n[Epoch 5 / 10] [Batch 780 / 938] [D loss: 0.675335] [G loss: 0.762357]\n[Epoch 5 / 10] [Batch 800 / 938] [D loss: 0.584290] [G loss: 0.861129]\n[Epoch 5 / 10] [Batch 820 / 938] [D loss: 0.548979] [G loss: 0.908118]\n[Epoch 5 / 10] [Batch 840 / 938] [D loss: 0.621749] [G loss: 0.939432]\n[Epoch 5 / 10] [Batch 860 / 938] [D loss: 0.752100] [G loss: 1.086986]\n[Epoch 5 / 10] [Batch 880 / 938] [D loss: 0.607071] [G loss: 0.937412]\n[Epoch 5 / 10] [Batch 900 / 938] [D loss: 0.498888] [G loss: 1.048731]\n[Epoch 5 / 10] [Batch 920 / 938] [D loss: 0.718571] [G loss: 0.713583]\n[Epoch 6 / 10] [Batch 0 / 938] [D loss: 0.528032] [G loss: 0.819984]\n[Epoch 6 / 10] [Batch 20 / 938] [D loss: 0.556903] [G loss: 0.788521]\n[Epoch 6 / 10] [Batch 40 / 938] [D loss: 0.565518] [G loss: 0.860583]\n[Epoch 6 / 10] [Batch 60 / 938] [D loss: 0.563467] [G loss: 1.041854]\n[Epoch 6 / 10] [Batch 80 / 938] [D loss: 0.664518] [G loss: 0.630834]\n[Epoch 6 / 10] [Batch 100 / 938] [D loss: 0.754755] [G loss: 0.716721]\n[Epoch 6 / 10] [Batch 120 / 938] [D loss: 0.521073] [G loss: 0.990806]\n[Epoch 6 / 10] [Batch 140 / 938] [D loss: 0.630223] [G loss: 0.519514]\n[Epoch 6 / 10] [Batch 160 / 938] [D loss: 0.627752] [G loss: 0.679893]\n[Epoch 6 / 10] [Batch 180 / 938] [D loss: 0.694638] [G loss: 0.914222]\n[Epoch 6 / 10] [Batch 200 / 938] [D loss: 0.629166] [G loss: 0.655424]\n[Epoch 6 / 10] [Batch 220 / 938] [D loss: 0.589636] [G loss: 1.004044]\n[Epoch 6 / 10] [Batch 240 / 938] [D loss: 0.662130] [G loss: 0.983432]\n[Epoch 6 / 10] [Batch 260 / 938] [D loss: 0.668151] [G loss: 0.961213]\n[Epoch 6 / 10] [Batch 280 / 938] [D loss: 0.620764] [G loss: 0.859618]\n[Epoch 6 / 10] [Batch 300 / 938] [D loss: 0.727870] [G loss: 1.009738]\n[Epoch 6 / 10] [Batch 320 / 938] [D loss: 0.631752] [G loss: 0.815932]\n[Epoch 6 / 10] [Batch 340 / 938] [D loss: 0.631954] [G loss: 1.402583]\n[Epoch 6 / 10] [Batch 360 / 938] [D loss: 0.626405] [G loss: 0.882613]\n[Epoch 6 / 10] [Batch 380 / 938] [D loss: 0.633478] [G loss: 0.983987]\n[Epoch 6 / 10] [Batch 400 / 938] [D loss: 0.596134] [G loss: 1.263799]\n[Epoch 6 / 10] [Batch 420 / 938] [D loss: 0.603647] [G loss: 1.162594]\n[Epoch 6 / 10] [Batch 440 / 938] [D loss: 0.610963] [G loss: 0.840960]\n[Epoch 6 / 10] [Batch 460 / 938] [D loss: 0.656932] [G loss: 1.282329]\n[Epoch 6 / 10] [Batch 480 / 938] [D loss: 0.497600] [G loss: 1.296366]\n[Epoch 6 / 10] [Batch 500 / 938] [D loss: 0.729128] [G loss: 1.051826]\n[Epoch 6 / 10] [Batch 520 / 938] [D loss: 0.601745] [G loss: 0.939838]\n[Epoch 6 / 10] [Batch 540 / 938] [D loss: 0.570168] [G loss: 1.040072]\n[Epoch 6 / 10] [Batch 560 / 938] [D loss: 0.547989] [G loss: 1.004073]\n[Epoch 6 / 10] [Batch 580 / 938] [D loss: 0.410181] [G loss: 1.056672]\n[Epoch 6 / 10] [Batch 600 / 938] [D loss: 0.495486] [G loss: 0.831953]\n[Epoch 6 / 10] [Batch 620 / 938] [D loss: 0.650451] [G loss: 0.652180]\n[Epoch 6 / 10] [Batch 640 / 938] [D loss: 0.397777] [G loss: 0.893917]\n[Epoch 6 / 10] [Batch 660 / 938] [D loss: 0.624755] [G loss: 0.806135]\n[Epoch 6 / 10] [Batch 680 / 938] [D loss: 0.612100] [G loss: 0.907091]\n[Epoch 6 / 10] [Batch 700 / 938] [D loss: 0.639974] [G loss: 0.914278]\n[Epoch 6 / 10] [Batch 720 / 938] [D loss: 0.673453] [G loss: 0.865186]\n[Epoch 6 / 10] [Batch 740 / 938] [D loss: 0.546856] [G loss: 0.966076]\n[Epoch 6 / 10] [Batch 760 / 938] [D loss: 0.653892] [G loss: 0.767574]\n[Epoch 6 / 10] [Batch 780 / 938] [D loss: 0.672728] [G loss: 1.037290]\n[Epoch 6 / 10] [Batch 800 / 938] [D loss: 0.669290] [G loss: 1.101946]\n[Epoch 6 / 10] [Batch 820 / 938] [D loss: 0.574455] [G loss: 0.973925]\n[Epoch 6 / 10] [Batch 840 / 938] [D loss: 0.469752] [G loss: 0.652386]\n[Epoch 6 / 10] [Batch 860 / 938] [D loss: 0.566498] [G loss: 1.296319]\n[Epoch 6 / 10] [Batch 880 / 938] [D loss: 0.656965] [G loss: 0.751951]\n[Epoch 6 / 10] [Batch 900 / 938] [D loss: 0.704609] [G loss: 0.864602]\n[Epoch 6 / 10] [Batch 920 / 938] [D loss: 0.554747] [G loss: 0.987212]\n[Epoch 7 / 10] [Batch 0 / 938] [D loss: 0.617789] [G loss: 1.061020]\n[Epoch 7 / 10] [Batch 20 / 938] [D loss: 0.549632] [G loss: 0.935592]\n[Epoch 7 / 10] [Batch 40 / 938] [D loss: 0.662664] [G loss: 0.899145]\n[Epoch 7 / 10] [Batch 60 / 938] [D loss: 0.627427] [G loss: 0.853282]\n[Epoch 7 / 10] [Batch 80 / 938] [D loss: 0.663119] [G loss: 0.739233]\n[Epoch 7 / 10] [Batch 100 / 938] [D loss: 0.687598] [G loss: 1.147354]\n[Epoch 7 / 10] [Batch 120 / 938] [D loss: 0.559685] [G loss: 0.719715]\n[Epoch 7 / 10] [Batch 140 / 938] [D loss: 0.662982] [G loss: 1.027865]\n[Epoch 7 / 10] [Batch 160 / 938] [D loss: 0.519541] [G loss: 1.056687]\n[Epoch 7 / 10] [Batch 180 / 938] [D loss: 0.561761] [G loss: 0.927540]\n[Epoch 7 / 10] [Batch 200 / 938] [D loss: 0.594998] [G loss: 0.934967]\n[Epoch 7 / 10] [Batch 220 / 938] [D loss: 0.542994] [G loss: 1.050053]\n[Epoch 7 / 10] [Batch 240 / 938] [D loss: 0.542117] [G loss: 0.662553]\n[Epoch 7 / 10] [Batch 260 / 938] [D loss: 0.557565] [G loss: 0.876713]\n[Epoch 7 / 10] [Batch 280 / 938] [D loss: 0.683414] [G loss: 1.154488]\n[Epoch 7 / 10] [Batch 300 / 938] [D loss: 0.665168] [G loss: 0.812226]\n[Epoch 7 / 10] [Batch 320 / 938] [D loss: 0.582497] [G loss: 0.816431]\n[Epoch 7 / 10] [Batch 340 / 938] [D loss: 0.519395] [G loss: 0.837776]\n[Epoch 7 / 10] [Batch 360 / 938] [D loss: 0.633869] [G loss: 0.897751]\n[Epoch 7 / 10] [Batch 380 / 938] [D loss: 0.584495] [G loss: 0.688333]\n[Epoch 7 / 10] [Batch 400 / 938] [D loss: 0.749549] [G loss: 0.719576]\n[Epoch 7 / 10] [Batch 420 / 938] [D loss: 0.675676] [G loss: 1.074565]\n[Epoch 7 / 10] [Batch 440 / 938] [D loss: 0.656379] [G loss: 1.086922]\n[Epoch 7 / 10] [Batch 460 / 938] [D loss: 0.625486] [G loss: 1.328088]\n[Epoch 7 / 10] [Batch 480 / 938] [D loss: 0.544513] [G loss: 0.649332]\n[Epoch 7 / 10] [Batch 500 / 938] [D loss: 0.636703] [G loss: 0.904995]\n[Epoch 7 / 10] [Batch 520 / 938] [D loss: 0.540123] [G loss: 0.915649]\n[Epoch 7 / 10] [Batch 540 / 938] [D loss: 0.503637] [G loss: 0.974127]\n[Epoch 7 / 10] [Batch 560 / 938] [D loss: 0.501032] [G loss: 0.978142]\n[Epoch 7 / 10] [Batch 580 / 938] [D loss: 0.674070] [G loss: 0.489875]\n[Epoch 7 / 10] [Batch 600 / 938] [D loss: 0.614533] [G loss: 0.761210]\n[Epoch 7 / 10] [Batch 620 / 938] [D loss: 0.530363] [G loss: 0.634461]\n[Epoch 7 / 10] [Batch 640 / 938] [D loss: 0.685522] [G loss: 1.032646]\n[Epoch 7 / 10] [Batch 660 / 938] [D loss: 0.483726] [G loss: 0.711110]\n[Epoch 7 / 10] [Batch 680 / 938] [D loss: 0.704187] [G loss: 0.752503]\n[Epoch 7 / 10] [Batch 700 / 938] [D loss: 0.665219] [G loss: 0.980496]\n[Epoch 7 / 10] [Batch 720 / 938] [D loss: 0.505407] [G loss: 1.203292]\n[Epoch 7 / 10] [Batch 740 / 938] [D loss: 0.584348] [G loss: 0.767619]\n[Epoch 7 / 10] [Batch 760 / 938] [D loss: 0.569400] [G loss: 1.092416]\n[Epoch 7 / 10] [Batch 780 / 938] [D loss: 0.479272] [G loss: 1.056661]\n[Epoch 7 / 10] [Batch 800 / 938] [D loss: 0.617315] [G loss: 0.628520]\n[Epoch 7 / 10] [Batch 820 / 938] [D loss: 0.615565] [G loss: 0.449072]\n[Epoch 7 / 10] [Batch 840 / 938] [D loss: 0.518663] [G loss: 0.975120]\n[Epoch 7 / 10] [Batch 860 / 938] [D loss: 0.546951] [G loss: 0.949560]\n[Epoch 7 / 10] [Batch 880 / 938] [D loss: 0.543218] [G loss: 0.830493]\n[Epoch 7 / 10] [Batch 900 / 938] [D loss: 0.567697] [G loss: 1.036159]\n[Epoch 7 / 10] [Batch 920 / 938] [D loss: 0.614299] [G loss: 0.870469]\n[Epoch 8 / 10] [Batch 0 / 938] [D loss: 0.584414] [G loss: 1.126080]\n[Epoch 8 / 10] [Batch 20 / 938] [D loss: 0.620930] [G loss: 0.559183]\n[Epoch 8 / 10] [Batch 40 / 938] [D loss: 0.596992] [G loss: 0.711524]\n[Epoch 8 / 10] [Batch 60 / 938] [D loss: 0.582384] [G loss: 0.783506]\n[Epoch 8 / 10] [Batch 80 / 938] [D loss: 0.565336] [G loss: 0.486986]\n[Epoch 8 / 10] [Batch 100 / 938] [D loss: 0.482335] [G loss: 0.854008]\n[Epoch 8 / 10] [Batch 120 / 938] [D loss: 0.666669] [G loss: 0.706450]\n[Epoch 8 / 10] [Batch 140 / 938] [D loss: 0.678191] [G loss: 1.105442]\n[Epoch 8 / 10] [Batch 160 / 938] [D loss: 0.590065] [G loss: 0.904365]\n[Epoch 8 / 10] [Batch 180 / 938] [D loss: 0.573378] [G loss: 1.199979]\n[Epoch 8 / 10] [Batch 200 / 938] [D loss: 0.577298] [G loss: 0.877220]\n[Epoch 8 / 10] [Batch 220 / 938] [D loss: 0.567009] [G loss: 1.026312]\n[Epoch 8 / 10] [Batch 240 / 938] [D loss: 0.715293] [G loss: 1.323659]\n[Epoch 8 / 10] [Batch 260 / 938] [D loss: 0.559154] [G loss: 1.274345]\n[Epoch 8 / 10] [Batch 280 / 938] [D loss: 0.602068] [G loss: 0.685103]\n[Epoch 8 / 10] [Batch 300 / 938] [D loss: 0.586069] [G loss: 0.815659]\n[Epoch 8 / 10] [Batch 320 / 938] [D loss: 0.599187] [G loss: 1.041269]\n[Epoch 8 / 10] [Batch 340 / 938] [D loss: 0.810960] [G loss: 1.005265]\n[Epoch 8 / 10] [Batch 360 / 938] [D loss: 0.564556] [G loss: 1.143527]\n[Epoch 8 / 10] [Batch 380 / 938] [D loss: 0.634366] [G loss: 0.747712]\n[Epoch 8 / 10] [Batch 400 / 938] [D loss: 0.540383] [G loss: 0.946145]\n[Epoch 8 / 10] [Batch 420 / 938] [D loss: 0.686868] [G loss: 0.866956]\n[Epoch 8 / 10] [Batch 440 / 938] [D loss: 0.634503] [G loss: 0.968268]\n[Epoch 8 / 10] [Batch 460 / 938] [D loss: 0.618147] [G loss: 0.835005]\n[Epoch 8 / 10] [Batch 480 / 938] [D loss: 0.490814] [G loss: 0.858203]\n[Epoch 8 / 10] [Batch 500 / 938] [D loss: 0.435502] [G loss: 0.955439]\n[Epoch 8 / 10] [Batch 520 / 938] [D loss: 0.618439] [G loss: 0.936925]\n[Epoch 8 / 10] [Batch 540 / 938] [D loss: 0.613811] [G loss: 1.174720]\n[Epoch 8 / 10] [Batch 560 / 938] [D loss: 0.665940] [G loss: 0.737830]\n[Epoch 8 / 10] [Batch 580 / 938] [D loss: 0.581394] [G loss: 0.600200]\n[Epoch 8 / 10] [Batch 600 / 938] [D loss: 0.732244] [G loss: 0.733290]\n[Epoch 8 / 10] [Batch 620 / 938] [D loss: 0.755660] [G loss: 0.500948]\n[Epoch 8 / 10] [Batch 640 / 938] [D loss: 0.628738] [G loss: 0.894308]\n[Epoch 8 / 10] [Batch 660 / 938] [D loss: 0.580002] [G loss: 1.197117]\n[Epoch 8 / 10] [Batch 680 / 938] [D loss: 0.819178] [G loss: 0.707535]\n[Epoch 8 / 10] [Batch 700 / 938] [D loss: 0.739430] [G loss: 0.708856]\n[Epoch 8 / 10] [Batch 720 / 938] [D loss: 0.662067] [G loss: 0.893243]\n[Epoch 8 / 10] [Batch 740 / 938] [D loss: 0.520051] [G loss: 0.805573]\n[Epoch 8 / 10] [Batch 760 / 938] [D loss: 0.616390] [G loss: 1.046785]\n[Epoch 8 / 10] [Batch 780 / 938] [D loss: 0.532710] [G loss: 1.341322]\n[Epoch 8 / 10] [Batch 800 / 938] [D loss: 0.669267] [G loss: 1.115593]\n[Epoch 8 / 10] [Batch 820 / 938] [D loss: 0.436419] [G loss: 1.266664]\n[Epoch 8 / 10] [Batch 840 / 938] [D loss: 0.473115] [G loss: 1.277726]\n[Epoch 8 / 10] [Batch 860 / 938] [D loss: 0.476695] [G loss: 1.355460]\n[Epoch 8 / 10] [Batch 880 / 938] [D loss: 0.555482] [G loss: 0.772478]\n[Epoch 8 / 10] [Batch 900 / 938] [D loss: 0.562016] [G loss: 0.823597]\n[Epoch 8 / 10] [Batch 920 / 938] [D loss: 0.669154] [G loss: 1.155791]\n[Epoch 9 / 10] [Batch 0 / 938] [D loss: 0.688671] [G loss: 0.472671]\n[Epoch 9 / 10] [Batch 20 / 938] [D loss: 0.734657] [G loss: 1.213831]\n[Epoch 9 / 10] [Batch 40 / 938] [D loss: 0.637439] [G loss: 0.474336]\n[Epoch 9 / 10] [Batch 60 / 938] [D loss: 0.539053] [G loss: 0.635718]\n[Epoch 9 / 10] [Batch 80 / 938] [D loss: 0.540153] [G loss: 0.748209]\n[Epoch 9 / 10] [Batch 100 / 938] [D loss: 0.665986] [G loss: 0.970328]\n[Epoch 9 / 10] [Batch 120 / 938] [D loss: 0.609128] [G loss: 1.105043]\n[Epoch 9 / 10] [Batch 140 / 938] [D loss: 0.706797] [G loss: 0.606425]\n[Epoch 9 / 10] [Batch 160 / 938] [D loss: 0.595368] [G loss: 1.049620]\n[Epoch 9 / 10] [Batch 180 / 938] [D loss: 0.461038] [G loss: 1.150426]\n[Epoch 9 / 10] [Batch 200 / 938] [D loss: 0.378236] [G loss: 0.948168]\n[Epoch 9 / 10] [Batch 220 / 938] [D loss: 0.572141] [G loss: 0.989823]\n[Epoch 9 / 10] [Batch 240 / 938] [D loss: 0.637583] [G loss: 0.774236]\n[Epoch 9 / 10] [Batch 260 / 938] [D loss: 0.565054] [G loss: 1.569593]\n[Epoch 9 / 10] [Batch 280 / 938] [D loss: 0.555674] [G loss: 1.524926]\n[Epoch 9 / 10] [Batch 300 / 938] [D loss: 0.580651] [G loss: 0.975617]\n[Epoch 9 / 10] [Batch 320 / 938] [D loss: 0.594210] [G loss: 0.764722]\n[Epoch 9 / 10] [Batch 340 / 938] [D loss: 0.615333] [G loss: 1.064327]\n[Epoch 9 / 10] [Batch 360 / 938] [D loss: 0.549906] [G loss: 1.006170]\n[Epoch 9 / 10] [Batch 380 / 938] [D loss: 0.560595] [G loss: 0.978555]\n[Epoch 9 / 10] [Batch 400 / 938] [D loss: 0.587004] [G loss: 0.605399]\n[Epoch 9 / 10] [Batch 420 / 938] [D loss: 0.551974] [G loss: 1.129132]\n[Epoch 9 / 10] [Batch 440 / 938] [D loss: 0.693209] [G loss: 0.602033]\n[Epoch 9 / 10] [Batch 460 / 938] [D loss: 0.667972] [G loss: 1.208309]\n[Epoch 9 / 10] [Batch 480 / 938] [D loss: 0.552576] [G loss: 1.223601]\n[Epoch 9 / 10] [Batch 500 / 938] [D loss: 0.557458] [G loss: 0.707816]\n[Epoch 9 / 10] [Batch 520 / 938] [D loss: 0.670314] [G loss: 1.173238]\n[Epoch 9 / 10] [Batch 540 / 938] [D loss: 0.703451] [G loss: 0.398036]\n[Epoch 9 / 10] [Batch 560 / 938] [D loss: 0.420500] [G loss: 0.963483]\n[Epoch 9 / 10] [Batch 580 / 938] [D loss: 0.701652] [G loss: 0.383230]\n[Epoch 9 / 10] [Batch 600 / 938] [D loss: 0.534523] [G loss: 1.088145]\n[Epoch 9 / 10] [Batch 620 / 938] [D loss: 0.584560] [G loss: 1.084937]\n[Epoch 9 / 10] [Batch 640 / 938] [D loss: 0.484623] [G loss: 0.894258]\n[Epoch 9 / 10] [Batch 660 / 938] [D loss: 0.758974] [G loss: 1.409565]\n[Epoch 9 / 10] [Batch 680 / 938] [D loss: 0.583924] [G loss: 0.757859]\n[Epoch 9 / 10] [Batch 700 / 938] [D loss: 0.579473] [G loss: 0.839768]\n[Epoch 9 / 10] [Batch 720 / 938] [D loss: 0.508508] [G loss: 1.104137]\n[Epoch 9 / 10] [Batch 740 / 938] [D loss: 0.463372] [G loss: 0.849500]\n[Epoch 9 / 10] [Batch 760 / 938] [D loss: 0.419767] [G loss: 0.884980]\n[Epoch 9 / 10] [Batch 780 / 938] [D loss: 0.516219] [G loss: 0.841641]\n[Epoch 9 / 10] [Batch 800 / 938] [D loss: 0.546955] [G loss: 1.173993]\n[Epoch 9 / 10] [Batch 820 / 938] [D loss: 0.585064] [G loss: 0.914479]\n[Epoch 9 / 10] [Batch 840 / 938] [D loss: 0.523754] [G loss: 1.647780]\n[Epoch 9 / 10] [Batch 860 / 938] [D loss: 0.594592] [G loss: 1.104750]\n[Epoch 9 / 10] [Batch 880 / 938] [D loss: 0.634393] [G loss: 0.899479]\n[Epoch 9 / 10] [Batch 900 / 938] [D loss: 0.471534] [G loss: 0.916553]\n[Epoch 9 / 10] [Batch 920 / 938] [D loss: 0.513165] [G loss: 0.988669]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}