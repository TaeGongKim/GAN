{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "challenging-imperial",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.023476,
     "end_time": "2021-04-26T14:15:54.983959",
     "exception": false,
     "start_time": "2021-04-26T14:15:54.960483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 0. INFO-GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-captain",
   "metadata": {
    "papermill": {
     "duration": 0.021559,
     "end_time": "2021-04-26T14:15:55.026896",
     "exception": false,
     "start_time": "2021-04-26T14:15:55.005337",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Reference\n",
    "- https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/infogan/infogan.py\n",
    "- paper : https://arxiv.org/abs/1606.03657"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-horror",
   "metadata": {
    "papermill": {
     "duration": 0.022325,
     "end_time": "2021-04-26T14:15:55.070284",
     "exception": false,
     "start_time": "2021-04-26T14:15:55.047959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sorted-psychiatry",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:15:55.118294Z",
     "iopub.status.busy": "2021-04-26T14:15:55.116741Z",
     "iopub.status.idle": "2021-04-26T14:16:04.381893Z",
     "shell.execute_reply": "2021-04-26T14:16:04.381315Z"
    },
    "papermill": {
     "duration": 9.290367,
     "end_time": "2021-04-26T14:16:04.382055",
     "exception": false,
     "start_time": "2021-04-26T14:15:55.091688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting easydict\r\n",
      "  Downloading easydict-1.9.tar.gz (6.4 kB)\r\n",
      "Building wheels for collected packages: easydict\r\n",
      "  Building wheel for easydict (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for easydict: filename=easydict-1.9-py3-none-any.whl size=6350 sha256=cbff704c6c73ef92ed008b4189ea7bb9ba35e78646101df9b12cbf14635b3f72\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/88/96/68/c2be18e7406804be2e593e1c37845f2dd20ac2ce1381ce40b0\r\n",
      "Successfully built easydict\r\n",
      "Installing collected packages: easydict\r\n",
      "Successfully installed easydict-1.9\r\n"
     ]
    }
   ],
   "source": [
    "!pip install easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "shared-capacity",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:04.438773Z",
     "iopub.status.busy": "2021-04-26T14:16:04.438031Z",
     "iopub.status.idle": "2021-04-26T14:16:05.798231Z",
     "shell.execute_reply": "2021-04-26T14:16:05.797293Z"
    },
    "papermill": {
     "duration": 1.39012,
     "end_time": "2021-04-26T14:16:05.798370",
     "exception": false,
     "start_time": "2021-04-26T14:16:04.408250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import easydict\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "regular-laundry",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:05.854878Z",
     "iopub.status.busy": "2021-04-26T14:16:05.854179Z",
     "iopub.status.idle": "2021-04-26T14:16:05.857357Z",
     "shell.execute_reply": "2021-04-26T14:16:05.856905Z"
    },
    "papermill": {
     "duration": 0.035023,
     "end_time": "2021-04-26T14:16:05.857486",
     "exception": false,
     "start_time": "2021-04-26T14:16:05.822463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"images/static/\", exist_ok = True)\n",
    "os.makedirs(\"images/varying_c1/\", exist_ok = True)\n",
    "os.makedirs(\"images/varying_c2/\", exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-arctic",
   "metadata": {
    "papermill": {
     "duration": 0.023782,
     "end_time": "2021-04-26T14:16:05.906772",
     "exception": false,
     "start_time": "2021-04-26T14:16:05.882990",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "appropriate-relations",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:05.959692Z",
     "iopub.status.busy": "2021-04-26T14:16:05.958960Z",
     "iopub.status.idle": "2021-04-26T14:16:05.961829Z",
     "shell.execute_reply": "2021-04-26T14:16:05.961357Z"
    },
    "papermill": {
     "duration": 0.031264,
     "end_time": "2021-04-26T14:16:05.961935",
     "exception": false,
     "start_time": "2021-04-26T14:16:05.930671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt = easydict.EasyDict({\"n_epochs\" : 5, \"batch_size\" : 64,\n",
    "                         \"lr\" : 0.0002, \"b1\" : 0.5, \"b2\" : 0.999,\n",
    "                         \"n_cpu\" : 8, \"latent_dim\" : 62,\n",
    "                         \"code_dim\" : 2, \"n_classes\" : 10,\n",
    "                         \"img_size\" : 32, \"channels\" : 1,\n",
    "                         \"sample_interval\" : 400})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "motivated-chart",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:06.013214Z",
     "iopub.status.busy": "2021-04-26T14:16:06.012667Z",
     "iopub.status.idle": "2021-04-26T14:16:06.015771Z",
     "shell.execute_reply": "2021-04-26T14:16:06.016246Z"
    },
    "papermill": {
     "duration": 0.030891,
     "end_time": "2021-04-26T14:16:06.016383",
     "exception": false,
     "start_time": "2021-04-26T14:16:05.985492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_epochs': 5, 'batch_size': 64, 'lr': 0.0002, 'b1': 0.5, 'b2': 0.999, 'n_cpu': 8, 'latent_dim': 62, 'code_dim': 2, 'n_classes': 10, 'img_size': 32, 'channels': 1, 'sample_interval': 400}\n"
     ]
    }
   ],
   "source": [
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "final-nitrogen",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:06.409586Z",
     "iopub.status.busy": "2021-04-26T14:16:06.408946Z",
     "iopub.status.idle": "2021-04-26T14:16:06.412221Z",
     "shell.execute_reply": "2021-04-26T14:16:06.411810Z"
    },
    "papermill": {
     "duration": 0.369412,
     "end_time": "2021-04-26T14:16:06.412341",
     "exception": false,
     "start_time": "2021-04-26T14:16:06.042929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "split-grave",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:06.467892Z",
     "iopub.status.busy": "2021-04-26T14:16:06.467333Z",
     "iopub.status.idle": "2021-04-26T14:16:06.472221Z",
     "shell.execute_reply": "2021-04-26T14:16:06.471669Z"
    },
    "papermill": {
     "duration": 0.034859,
     "end_time": "2021-04-26T14:16:06.472335",
     "exception": false,
     "start_time": "2021-04-26T14:16:06.437476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-shaft",
   "metadata": {
    "papermill": {
     "duration": 0.024685,
     "end_time": "2021-04-26T14:16:06.523556",
     "exception": false,
     "start_time": "2021-04-26T14:16:06.498871",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-belize",
   "metadata": {
    "papermill": {
     "duration": 0.024693,
     "end_time": "2021-04-26T14:16:06.574270",
     "exception": false,
     "start_time": "2021-04-26T14:16:06.549577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.1 Weights Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "statistical-appointment",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:06.629245Z",
     "iopub.status.busy": "2021-04-26T14:16:06.628573Z",
     "iopub.status.idle": "2021-04-26T14:16:06.631567Z",
     "shell.execute_reply": "2021-04-26T14:16:06.631954Z"
    },
    "papermill": {
     "duration": 0.033126,
     "end_time": "2021-04-26T14:16:06.632081",
     "exception": false,
     "start_time": "2021-04-26T14:16:06.598955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-acquisition",
   "metadata": {
    "papermill": {
     "duration": 0.02459,
     "end_time": "2021-04-26T14:16:06.681361",
     "exception": false,
     "start_time": "2021-04-26T14:16:06.656771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.2 One-hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "finite-frost",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:06.736840Z",
     "iopub.status.busy": "2021-04-26T14:16:06.736032Z",
     "iopub.status.idle": "2021-04-26T14:16:06.738911Z",
     "shell.execute_reply": "2021-04-26T14:16:06.738500Z"
    },
    "papermill": {
     "duration": 0.033054,
     "end_time": "2021-04-26T14:16:06.739036",
     "exception": false,
     "start_time": "2021-04-26T14:16:06.705982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_categorical(y, num_columns):\n",
    "    \"\"\"\n",
    "        Return one-hot encoded Variable\n",
    "    \"\"\"\n",
    "    y_cat = np.zeros((y.shape[0], num_columns))\n",
    "    y_cat[range(y.shape[0]), y] = 1.0\n",
    "    \n",
    "    return Variable(FloatTensor(y_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-penny",
   "metadata": {
    "papermill": {
     "duration": 0.027367,
     "end_time": "2021-04-26T14:16:06.791936",
     "exception": false,
     "start_time": "2021-04-26T14:16:06.764569",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.3 Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "atlantic-inventory",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:06.856791Z",
     "iopub.status.busy": "2021-04-26T14:16:06.855450Z",
     "iopub.status.idle": "2021-04-26T14:16:06.859205Z",
     "shell.execute_reply": "2021-04-26T14:16:06.858651Z"
    },
    "papermill": {
     "duration": 0.040928,
     "end_time": "2021-04-26T14:16:06.859339",
     "exception": false,
     "start_time": "2021-04-26T14:16:06.818411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        # code dimension ?????\n",
    "        input_dim = opt.latent_dim + opt.n_classes + opt.code_dim\n",
    "        \n",
    "        # Initial size before upsampling\n",
    "        # 2 ** #upsampling\n",
    "        self.init_size = opt.img_size // 4\n",
    "        self.l1 = nn.Sequential(nn.Linear(input_dim, 128 * self.init_size ** 2))\n",
    "        \n",
    "        self.conv_blocks = nn.Sequential(nn.BatchNorm2d(128),\n",
    "                                         nn.Upsample(scale_factor = 2),\n",
    "                                         nn.Conv2d(128, 128, 3, stride = 1, padding = 1),\n",
    "                                         nn.BatchNorm2d(128, 0.8),\n",
    "                                         nn.LeakyReLU(0.2, inplace = True),\n",
    "                                         nn.Upsample(scale_factor = 2),\n",
    "                                         nn.Conv2d(128, 64, 3, stride = 1, padding = 1),\n",
    "                                         nn.BatchNorm2d(64, 0.8),\n",
    "                                         nn.LeakyReLU(0.2, inplace = True),\n",
    "                                         nn.Conv2d(64, opt.channels, 3, stride = 1, padding = 1),\n",
    "                                         nn.Tanh()\n",
    "                                        )\n",
    "        \n",
    "    def forward(self, noise, labels, code):\n",
    "        # Concatenates\n",
    "        gen_input = torch.cat((noise, labels, code), -1)\n",
    "        out = self.l1(gen_input)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-reservation",
   "metadata": {
    "papermill": {
     "duration": 0.027021,
     "end_time": "2021-04-26T14:16:06.914124",
     "exception": false,
     "start_time": "2021-04-26T14:16:06.887103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.4 Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "electric-camping",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:06.976932Z",
     "iopub.status.busy": "2021-04-26T14:16:06.976121Z",
     "iopub.status.idle": "2021-04-26T14:16:06.979159Z",
     "shell.execute_reply": "2021-04-26T14:16:06.979524Z"
    },
    "papermill": {
     "duration": 0.038431,
     "end_time": "2021-04-26T14:16:06.979666",
     "exception": false,
     "start_time": "2021-04-26T14:16:06.941235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        def discriminator_block(in_filters, out_filters, bn = True):\n",
    "            \"\"\"\n",
    "                Returns layers of each discriminator block\n",
    "            \"\"\"\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1),\n",
    "                     nn.LeakyReLU(0.2, inplace = True),\n",
    "                     nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "        \n",
    "        self.conv_blocks = nn.Sequential(*discriminator_block(opt.channels, 16, bn = False),\n",
    "                                         *discriminator_block(16, 32),\n",
    "                                         *discriminator_block(32, 64),\n",
    "                                         *discriminator_block(64, 128)\n",
    "                                        )\n",
    "        \n",
    "        # The height and width of downsampled image\n",
    "        ds_size = opt.img_size // 2 ** 4\n",
    "        \n",
    "        # Output layers\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1))\n",
    "        self.aux_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, opt.n_classes), nn.Softmax())\n",
    "        self.latent_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, opt.code_dim))\n",
    "        \n",
    "    def forward(self, img):\n",
    "        out = self.conv_blocks(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "        label = self.aux_layer(out)\n",
    "        latent_code = self.latent_layer(out)\n",
    "        \n",
    "        return validity, label, latent_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-franchise",
   "metadata": {
    "papermill": {
     "duration": 0.025987,
     "end_time": "2021-04-26T14:16:07.031739",
     "exception": false,
     "start_time": "2021-04-26T14:16:07.005752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.5 Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "systematic-sunrise",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:07.090143Z",
     "iopub.status.busy": "2021-04-26T14:16:07.089358Z",
     "iopub.status.idle": "2021-04-26T14:16:07.092126Z",
     "shell.execute_reply": "2021-04-26T14:16:07.091721Z"
    },
    "papermill": {
     "duration": 0.034344,
     "end_time": "2021-04-26T14:16:07.092234",
     "exception": false,
     "start_time": "2021-04-26T14:16:07.057890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "adversarial_loss = torch.nn.MSELoss()\n",
    "categorical_loss = torch.nn.CrossEntropyLoss()\n",
    "continuous_loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abroad-spyware",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:07.146797Z",
     "iopub.status.busy": "2021-04-26T14:16:07.145940Z",
     "iopub.status.idle": "2021-04-26T14:16:07.148727Z",
     "shell.execute_reply": "2021-04-26T14:16:07.148322Z"
    },
    "papermill": {
     "duration": 0.031032,
     "end_time": "2021-04-26T14:16:07.148832",
     "exception": false,
     "start_time": "2021-04-26T14:16:07.117800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss Weights\n",
    "lambda_cat = 1\n",
    "lambda_con = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-sacramento",
   "metadata": {
    "papermill": {
     "duration": 0.026155,
     "end_time": "2021-04-26T14:16:07.200390",
     "exception": false,
     "start_time": "2021-04-26T14:16:07.174235",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Data Loader and Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-honor",
   "metadata": {
    "papermill": {
     "duration": 0.028675,
     "end_time": "2021-04-26T14:16:07.257997",
     "exception": false,
     "start_time": "2021-04-26T14:16:07.229322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.1 Model Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "streaming-breakfast",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:07.315084Z",
     "iopub.status.busy": "2021-04-26T14:16:07.314519Z",
     "iopub.status.idle": "2021-04-26T14:16:07.357390Z",
     "shell.execute_reply": "2021-04-26T14:16:07.356873Z"
    },
    "papermill": {
     "duration": 0.073118,
     "end_time": "2021-04-26T14:16:07.357505",
     "exception": false,
     "start_time": "2021-04-26T14:16:07.284387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ceramic-vancouver",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:07.414830Z",
     "iopub.status.busy": "2021-04-26T14:16:07.414220Z",
     "iopub.status.idle": "2021-04-26T14:16:11.831285Z",
     "shell.execute_reply": "2021-04-26T14:16:11.830808Z"
    },
    "papermill": {
     "duration": 4.448694,
     "end_time": "2021-04-26T14:16:11.831418",
     "exception": false,
     "start_time": "2021-04-26T14:16:07.382724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "    categorical_loss.cuda()\n",
    "    continuous_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "intermediate-hammer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:11.888863Z",
     "iopub.status.busy": "2021-04-26T14:16:11.888206Z",
     "iopub.status.idle": "2021-04-26T14:16:11.896941Z",
     "shell.execute_reply": "2021-04-26T14:16:11.897450Z"
    },
    "papermill": {
     "duration": 0.039526,
     "end_time": "2021-04-26T14:16:11.897605",
     "exception": false,
     "start_time": "2021-04-26T14:16:11.858079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (conv_blocks): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Dropout2d(p=0.25, inplace=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Dropout2d(p=0.25, inplace=False)\n",
       "    (6): BatchNorm2d(32, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (9): Dropout2d(p=0.25, inplace=False)\n",
       "    (10): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (12): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (13): Dropout2d(p=0.25, inplace=False)\n",
       "    (14): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (adv_layer): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (aux_layer): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (1): Softmax(dim=None)\n",
       "  )\n",
       "  (latent_layer): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize weights\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-distance",
   "metadata": {
    "papermill": {
     "duration": 0.025883,
     "end_time": "2021-04-26T14:16:11.949268",
     "exception": false,
     "start_time": "2021-04-26T14:16:11.923385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.2 Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "romantic-service",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:12.027520Z",
     "iopub.status.busy": "2021-04-26T14:16:12.006251Z",
     "iopub.status.idle": "2021-04-26T14:16:18.430249Z",
     "shell.execute_reply": "2021-04-26T14:16:18.429812Z"
    },
    "papermill": {
     "duration": 6.454873,
     "end_time": "2021-04-26T14:16:18.430374",
     "exception": false,
     "start_time": "2021-04-26T14:16:11.975501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-26 14:16:12--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\r\n",
      "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\r\n",
      "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\r\n",
      "--2021-04-26 14:16:12--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\r\n",
      "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: unspecified [application/x-gzip]\r\n",
      "Saving to: ‘MNIST.tar.gz’\r\n",
      "\r\n",
      "MNIST.tar.gz            [               <=>  ]  33.20M  10.4MB/s    in 3.2s    \r\n",
      "\r\n",
      "2021-04-26 14:16:16 (10.4 MB/s) - ‘MNIST.tar.gz’ saved [34813078]\r\n",
      "\r\n",
      "MNIST/\r\n",
      "MNIST/raw/\r\n",
      "MNIST/raw/train-labels-idx1-ubyte\r\n",
      "MNIST/raw/t10k-labels-idx1-ubyte.gz\r\n",
      "MNIST/raw/t10k-labels-idx1-ubyte\r\n",
      "MNIST/raw/t10k-images-idx3-ubyte.gz\r\n",
      "MNIST/raw/train-images-idx3-ubyte\r\n",
      "MNIST/raw/train-labels-idx1-ubyte.gz\r\n",
      "MNIST/raw/t10k-images-idx3-ubyte\r\n",
      "MNIST/raw/train-images-idx3-ubyte.gz\r\n",
      "MNIST/processed/\r\n",
      "MNIST/processed/training.pt\r\n",
      "MNIST/processed/test.pt\r\n"
     ]
    }
   ],
   "source": [
    "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
    "!tar -zxvf MNIST.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "express-checklist",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:18.506402Z",
     "iopub.status.busy": "2021-04-26T14:16:18.505791Z",
     "iopub.status.idle": "2021-04-26T14:16:18.536511Z",
     "shell.execute_reply": "2021-04-26T14:16:18.536104Z"
    },
    "papermill": {
     "duration": 0.07024,
     "end_time": "2021-04-26T14:16:18.536626",
     "exception": false,
     "start_time": "2021-04-26T14:16:18.466386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Condigure data loader\n",
    "os.makedirs(\"./\", exist_ok = True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "                datasets.MNIST(\n",
    "                    \"./\",\n",
    "                    train = True,\n",
    "                    download = True,\n",
    "                    transform = transforms.Compose(\n",
    "                        [transforms.Resize(opt.img_size), transforms.ToTensor(),\n",
    "                         transforms.Normalize([0.5], [0.5])]\n",
    "                    )\n",
    "                ),\n",
    "                batch_size = opt.batch_size,\n",
    "                shuffle = True\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-egypt",
   "metadata": {
    "papermill": {
     "duration": 0.032754,
     "end_time": "2021-04-26T14:16:18.602608",
     "exception": false,
     "start_time": "2021-04-26T14:16:18.569854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.3 Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "descending-receipt",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:18.675042Z",
     "iopub.status.busy": "2021-04-26T14:16:18.674333Z",
     "iopub.status.idle": "2021-04-26T14:16:18.677076Z",
     "shell.execute_reply": "2021-04-26T14:16:18.676660Z"
    },
    "papermill": {
     "duration": 0.041774,
     "end_time": "2021-04-26T14:16:18.677220",
     "exception": false,
     "start_time": "2021-04-26T14:16:18.635446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr = opt.lr, betas = (opt.b1, opt.b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr = opt.lr, betas = (opt.b1, opt.b2))\n",
    "optimizer_info = torch.optim.Adam(itertools.chain(generator.parameters(),\n",
    "                                                   discriminator.parameters()),\n",
    "                                  lr = opt.lr, betas = (opt.b1, opt.b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "stretch-parade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:18.748050Z",
     "iopub.status.busy": "2021-04-26T14:16:18.747212Z",
     "iopub.status.idle": "2021-04-26T14:16:18.750047Z",
     "shell.execute_reply": "2021-04-26T14:16:18.749625Z"
    },
    "papermill": {
     "duration": 0.03979,
     "end_time": "2021-04-26T14:16:18.750153",
     "exception": false,
     "start_time": "2021-04-26T14:16:18.710363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "pharmaceutical-artwork",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:18.821222Z",
     "iopub.status.busy": "2021-04-26T14:16:18.820732Z",
     "iopub.status.idle": "2021-04-26T14:16:18.826953Z",
     "shell.execute_reply": "2021-04-26T14:16:18.827407Z"
    },
    "papermill": {
     "duration": 0.044272,
     "end_time": "2021-04-26T14:16:18.827537",
     "exception": false,
     "start_time": "2021-04-26T14:16:18.783265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Static generator inputs for sampling\n",
    "static_z = Variable(FloatTensor(np.zeros((opt.n_classes ** 2, opt.latent_dim))))\n",
    "static_label = to_categorical(np.array([num for _ in range(opt.n_classes) for num in range(opt.n_classes)]),\n",
    "                              num_columns = opt.n_classes\n",
    "                             )\n",
    "static_code = Variable(FloatTensor(np.zeros((opt.n_classes ** 2, opt.code_dim))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-newfoundland",
   "metadata": {
    "papermill": {
     "duration": 0.03273,
     "end_time": "2021-04-26T14:16:18.893717",
     "exception": false,
     "start_time": "2021-04-26T14:16:18.860987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.4 Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "billion-contact",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:18.970752Z",
     "iopub.status.busy": "2021-04-26T14:16:18.969998Z",
     "iopub.status.idle": "2021-04-26T14:16:18.972157Z",
     "shell.execute_reply": "2021-04-26T14:16:18.972552Z"
    },
    "papermill": {
     "duration": 0.04382,
     "end_time": "2021-04-26T14:16:18.972686",
     "exception": false,
     "start_time": "2021-04-26T14:16:18.928866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_image(n_row, batches_done):\n",
    "    \"\"\"\n",
    "        Saves a grid of generated digits ranging from 0 to n_classes\n",
    "    \"\"\"\n",
    "    # Static sample\n",
    "    z = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, opt.latent_dim))))\n",
    "    static_sample = generator(z, static_label, static_code)\n",
    "    save_image(static_sample.data, \"images/static/%d.png\" % batches_done, nrow = n_row, normalize = True)\n",
    "    \n",
    "    # Get varied c1 and c2\n",
    "    zeros = np.zeros((n_row ** 2, 1))\n",
    "    c_varied = np.repeat(np.linspace(-1, 1, n_row)[:, np.newaxis], n_row, 0)\n",
    "    c1 = Variable(FloatTensor(np.concatenate((c_varied, zeros), -1)))\n",
    "    c2 = Variable(FloatTensor(np.concatenate((zeros, c_varied), -1)))\n",
    "    sample1 = generator(static_z, static_label, c1)\n",
    "    sample2 = generator(static_z, static_label, c2)\n",
    "    save_image(sample1.data, \"images/varying_c1/%d.png\" % batches_done, nrow = n_row, normalize = True)\n",
    "    save_image(sample2.data, \"images/varying_c2/%d.png\" % batches_done, nrow = n_row, normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-rwanda",
   "metadata": {
    "papermill": {
     "duration": 0.033528,
     "end_time": "2021-04-26T14:16:19.039445",
     "exception": false,
     "start_time": "2021-04-26T14:16:19.005917",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.5 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "preliminary-living",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T14:16:19.128443Z",
     "iopub.status.busy": "2021-04-26T14:16:19.127781Z",
     "iopub.status.idle": "2021-04-26T14:20:17.873890Z",
     "shell.execute_reply": "2021-04-26T14:20:17.873414Z"
    },
    "papermill": {
     "duration": 238.798264,
     "end_time": "2021-04-26T14:20:17.874021",
     "exception": false,
     "start_time": "2021-04-26T14:16:19.075757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/5] [Batch 0/938] [D loss: 0.505319] [G loss: 1.010333] [info loss: 2.336777]\n",
      "[Epoch 0/5] [Batch 20/938] [D loss: 0.393967] [G loss: 0.746975] [info loss: 2.333571]\n",
      "[Epoch 0/5] [Batch 40/938] [D loss: 0.212067] [G loss: 0.326726] [info loss: 2.328879]\n",
      "[Epoch 0/5] [Batch 60/938] [D loss: 0.075085] [G loss: 0.653329] [info loss: 2.256758]\n",
      "[Epoch 0/5] [Batch 80/938] [D loss: 0.099803] [G loss: 0.777411] [info loss: 2.034130]\n",
      "[Epoch 0/5] [Batch 100/938] [D loss: 0.117710] [G loss: 0.928423] [info loss: 1.702694]\n",
      "[Epoch 0/5] [Batch 120/938] [D loss: 0.134788] [G loss: 0.714284] [info loss: 1.617078]\n",
      "[Epoch 0/5] [Batch 140/938] [D loss: 0.141017] [G loss: 0.601593] [info loss: 1.604203]\n",
      "[Epoch 0/5] [Batch 160/938] [D loss: 0.204894] [G loss: 0.441721] [info loss: 1.566506]\n",
      "[Epoch 0/5] [Batch 180/938] [D loss: 0.220423] [G loss: 0.470623] [info loss: 1.586051]\n",
      "[Epoch 0/5] [Batch 200/938] [D loss: 0.193920] [G loss: 0.371933] [info loss: 1.549565]\n",
      "[Epoch 0/5] [Batch 220/938] [D loss: 0.216496] [G loss: 0.424424] [info loss: 1.572828]\n",
      "[Epoch 0/5] [Batch 240/938] [D loss: 0.210405] [G loss: 0.524163] [info loss: 1.527410]\n",
      "[Epoch 0/5] [Batch 260/938] [D loss: 0.219335] [G loss: 0.389655] [info loss: 1.525917]\n",
      "[Epoch 0/5] [Batch 280/938] [D loss: 0.176190] [G loss: 0.409694] [info loss: 1.526065]\n",
      "[Epoch 0/5] [Batch 300/938] [D loss: 0.217966] [G loss: 0.396752] [info loss: 1.545149]\n",
      "[Epoch 0/5] [Batch 320/938] [D loss: 0.194431] [G loss: 0.523861] [info loss: 1.508459]\n",
      "[Epoch 0/5] [Batch 340/938] [D loss: 0.223163] [G loss: 0.478972] [info loss: 1.508289]\n",
      "[Epoch 0/5] [Batch 360/938] [D loss: 0.217480] [G loss: 0.314736] [info loss: 1.496742]\n",
      "[Epoch 0/5] [Batch 380/938] [D loss: 0.193648] [G loss: 0.429018] [info loss: 1.501875]\n",
      "[Epoch 0/5] [Batch 400/938] [D loss: 0.205652] [G loss: 0.424938] [info loss: 1.511893]\n",
      "[Epoch 0/5] [Batch 420/938] [D loss: 0.213437] [G loss: 0.441932] [info loss: 1.504856]\n",
      "[Epoch 0/5] [Batch 440/938] [D loss: 0.215741] [G loss: 0.438307] [info loss: 1.513628]\n",
      "[Epoch 0/5] [Batch 460/938] [D loss: 0.209442] [G loss: 0.464076] [info loss: 1.490100]\n",
      "[Epoch 0/5] [Batch 480/938] [D loss: 0.218776] [G loss: 0.466020] [info loss: 1.504690]\n",
      "[Epoch 0/5] [Batch 500/938] [D loss: 0.224880] [G loss: 0.395615] [info loss: 1.506170]\n",
      "[Epoch 0/5] [Batch 520/938] [D loss: 0.218740] [G loss: 0.379646] [info loss: 1.497360]\n",
      "[Epoch 0/5] [Batch 540/938] [D loss: 0.230073] [G loss: 0.347388] [info loss: 1.512349]\n",
      "[Epoch 0/5] [Batch 560/938] [D loss: 0.235364] [G loss: 0.372603] [info loss: 1.500453]\n",
      "[Epoch 0/5] [Batch 580/938] [D loss: 0.226212] [G loss: 0.434670] [info loss: 1.490544]\n",
      "[Epoch 0/5] [Batch 600/938] [D loss: 0.223639] [G loss: 0.439046] [info loss: 1.488245]\n",
      "[Epoch 0/5] [Batch 620/938] [D loss: 0.231038] [G loss: 0.421167] [info loss: 1.490836]\n",
      "[Epoch 0/5] [Batch 640/938] [D loss: 0.209090] [G loss: 0.422586] [info loss: 1.481920]\n",
      "[Epoch 0/5] [Batch 660/938] [D loss: 0.208425] [G loss: 0.310106] [info loss: 1.485404]\n",
      "[Epoch 0/5] [Batch 680/938] [D loss: 0.199114] [G loss: 0.304266] [info loss: 1.486569]\n",
      "[Epoch 0/5] [Batch 700/938] [D loss: 0.220524] [G loss: 0.432672] [info loss: 1.491272]\n",
      "[Epoch 0/5] [Batch 720/938] [D loss: 0.207729] [G loss: 0.386608] [info loss: 1.496694]\n",
      "[Epoch 0/5] [Batch 740/938] [D loss: 0.226509] [G loss: 0.348992] [info loss: 1.476856]\n",
      "[Epoch 0/5] [Batch 760/938] [D loss: 0.227456] [G loss: 0.313496] [info loss: 1.499037]\n",
      "[Epoch 0/5] [Batch 780/938] [D loss: 0.242429] [G loss: 0.334671] [info loss: 1.489224]\n",
      "[Epoch 0/5] [Batch 800/938] [D loss: 0.176148] [G loss: 0.353180] [info loss: 1.494698]\n",
      "[Epoch 0/5] [Batch 820/938] [D loss: 0.195273] [G loss: 0.384522] [info loss: 1.490468]\n",
      "[Epoch 0/5] [Batch 840/938] [D loss: 0.231662] [G loss: 0.425289] [info loss: 1.486531]\n",
      "[Epoch 0/5] [Batch 860/938] [D loss: 0.231464] [G loss: 0.327867] [info loss: 1.493958]\n",
      "[Epoch 0/5] [Batch 880/938] [D loss: 0.190951] [G loss: 0.353894] [info loss: 1.508823]\n",
      "[Epoch 0/5] [Batch 900/938] [D loss: 0.221692] [G loss: 0.364704] [info loss: 1.488610]\n",
      "[Epoch 0/5] [Batch 920/938] [D loss: 0.213658] [G loss: 0.342295] [info loss: 1.502971]\n",
      "[Epoch 1/5] [Batch 0/938] [D loss: 0.219326] [G loss: 0.464188] [info loss: 1.483069]\n",
      "[Epoch 1/5] [Batch 20/938] [D loss: 0.240006] [G loss: 0.261783] [info loss: 1.475643]\n",
      "[Epoch 1/5] [Batch 40/938] [D loss: 0.239428] [G loss: 0.260248] [info loss: 1.482780]\n",
      "[Epoch 1/5] [Batch 60/938] [D loss: 0.219237] [G loss: 0.356385] [info loss: 1.491168]\n",
      "[Epoch 1/5] [Batch 80/938] [D loss: 0.241143] [G loss: 0.324930] [info loss: 1.484503]\n",
      "[Epoch 1/5] [Batch 100/938] [D loss: 0.218575] [G loss: 0.308288] [info loss: 1.487358]\n",
      "[Epoch 1/5] [Batch 120/938] [D loss: 0.225260] [G loss: 0.346085] [info loss: 1.497708]\n",
      "[Epoch 1/5] [Batch 140/938] [D loss: 0.232014] [G loss: 0.350687] [info loss: 1.479718]\n",
      "[Epoch 1/5] [Batch 160/938] [D loss: 0.208132] [G loss: 0.373536] [info loss: 1.475753]\n",
      "[Epoch 1/5] [Batch 180/938] [D loss: 0.229653] [G loss: 0.318279] [info loss: 1.495065]\n",
      "[Epoch 1/5] [Batch 200/938] [D loss: 0.192447] [G loss: 0.253206] [info loss: 1.501165]\n",
      "[Epoch 1/5] [Batch 220/938] [D loss: 0.250217] [G loss: 0.407167] [info loss: 1.478693]\n",
      "[Epoch 1/5] [Batch 240/938] [D loss: 0.223785] [G loss: 0.344394] [info loss: 1.483391]\n",
      "[Epoch 1/5] [Batch 260/938] [D loss: 0.223704] [G loss: 0.327824] [info loss: 1.490089]\n",
      "[Epoch 1/5] [Batch 280/938] [D loss: 0.240449] [G loss: 0.270284] [info loss: 1.479900]\n",
      "[Epoch 1/5] [Batch 300/938] [D loss: 0.214623] [G loss: 0.392870] [info loss: 1.476193]\n",
      "[Epoch 1/5] [Batch 320/938] [D loss: 0.191478] [G loss: 0.350862] [info loss: 1.500363]\n",
      "[Epoch 1/5] [Batch 340/938] [D loss: 0.238488] [G loss: 0.347633] [info loss: 1.488981]\n",
      "[Epoch 1/5] [Batch 360/938] [D loss: 0.231229] [G loss: 0.304694] [info loss: 1.483626]\n",
      "[Epoch 1/5] [Batch 380/938] [D loss: 0.237805] [G loss: 0.327102] [info loss: 1.481753]\n",
      "[Epoch 1/5] [Batch 400/938] [D loss: 0.218929] [G loss: 0.309425] [info loss: 1.508400]\n",
      "[Epoch 1/5] [Batch 420/938] [D loss: 0.231513] [G loss: 0.410003] [info loss: 1.481325]\n",
      "[Epoch 1/5] [Batch 440/938] [D loss: 0.201690] [G loss: 0.354822] [info loss: 1.494009]\n",
      "[Epoch 1/5] [Batch 460/938] [D loss: 0.203532] [G loss: 0.307133] [info loss: 1.489658]\n",
      "[Epoch 1/5] [Batch 480/938] [D loss: 0.257204] [G loss: 0.281877] [info loss: 1.478274]\n",
      "[Epoch 1/5] [Batch 500/938] [D loss: 0.220158] [G loss: 0.376718] [info loss: 1.491989]\n",
      "[Epoch 1/5] [Batch 520/938] [D loss: 0.232797] [G loss: 0.360223] [info loss: 1.481699]\n",
      "[Epoch 1/5] [Batch 540/938] [D loss: 0.221711] [G loss: 0.349842] [info loss: 1.494408]\n",
      "[Epoch 1/5] [Batch 560/938] [D loss: 0.248216] [G loss: 0.361441] [info loss: 1.487403]\n",
      "[Epoch 1/5] [Batch 580/938] [D loss: 0.227932] [G loss: 0.350739] [info loss: 1.483304]\n",
      "[Epoch 1/5] [Batch 600/938] [D loss: 0.227221] [G loss: 0.349762] [info loss: 1.479246]\n",
      "[Epoch 1/5] [Batch 620/938] [D loss: 0.213860] [G loss: 0.356264] [info loss: 1.482839]\n",
      "[Epoch 1/5] [Batch 640/938] [D loss: 0.208237] [G loss: 0.352799] [info loss: 1.472665]\n",
      "[Epoch 1/5] [Batch 660/938] [D loss: 0.208284] [G loss: 0.327387] [info loss: 1.474821]\n",
      "[Epoch 1/5] [Batch 680/938] [D loss: 0.202130] [G loss: 0.369903] [info loss: 1.477165]\n",
      "[Epoch 1/5] [Batch 700/938] [D loss: 0.229464] [G loss: 0.287322] [info loss: 1.487628]\n",
      "[Epoch 1/5] [Batch 720/938] [D loss: 0.216351] [G loss: 0.405710] [info loss: 1.478270]\n",
      "[Epoch 1/5] [Batch 740/938] [D loss: 0.210628] [G loss: 0.400930] [info loss: 1.492689]\n",
      "[Epoch 1/5] [Batch 760/938] [D loss: 0.216406] [G loss: 0.304460] [info loss: 1.488500]\n",
      "[Epoch 1/5] [Batch 780/938] [D loss: 0.228316] [G loss: 0.321329] [info loss: 1.473297]\n",
      "[Epoch 1/5] [Batch 800/938] [D loss: 0.225411] [G loss: 0.289291] [info loss: 1.489259]\n",
      "[Epoch 1/5] [Batch 820/938] [D loss: 0.254700] [G loss: 0.260435] [info loss: 1.486995]\n",
      "[Epoch 1/5] [Batch 840/938] [D loss: 0.225479] [G loss: 0.370658] [info loss: 1.494053]\n",
      "[Epoch 1/5] [Batch 860/938] [D loss: 0.198699] [G loss: 0.337639] [info loss: 1.478447]\n",
      "[Epoch 1/5] [Batch 880/938] [D loss: 0.205089] [G loss: 0.364342] [info loss: 1.473737]\n",
      "[Epoch 1/5] [Batch 900/938] [D loss: 0.232456] [G loss: 0.329252] [info loss: 1.493252]\n",
      "[Epoch 1/5] [Batch 920/938] [D loss: 0.217953] [G loss: 0.332790] [info loss: 1.479910]\n",
      "[Epoch 2/5] [Batch 0/938] [D loss: 0.216959] [G loss: 0.294212] [info loss: 1.482059]\n",
      "[Epoch 2/5] [Batch 20/938] [D loss: 0.242301] [G loss: 0.274234] [info loss: 1.499168]\n",
      "[Epoch 2/5] [Batch 40/938] [D loss: 0.206152] [G loss: 0.309261] [info loss: 1.476645]\n",
      "[Epoch 2/5] [Batch 60/938] [D loss: 0.195537] [G loss: 0.269360] [info loss: 1.489701]\n",
      "[Epoch 2/5] [Batch 80/938] [D loss: 0.202680] [G loss: 0.322576] [info loss: 1.481641]\n",
      "[Epoch 2/5] [Batch 100/938] [D loss: 0.229862] [G loss: 0.293966] [info loss: 1.491148]\n",
      "[Epoch 2/5] [Batch 120/938] [D loss: 0.218752] [G loss: 0.348531] [info loss: 1.477390]\n",
      "[Epoch 2/5] [Batch 140/938] [D loss: 0.218257] [G loss: 0.384109] [info loss: 1.474977]\n",
      "[Epoch 2/5] [Batch 160/938] [D loss: 0.199658] [G loss: 0.401797] [info loss: 1.476837]\n",
      "[Epoch 2/5] [Batch 180/938] [D loss: 0.221731] [G loss: 0.388033] [info loss: 1.475447]\n",
      "[Epoch 2/5] [Batch 200/938] [D loss: 0.196163] [G loss: 0.370008] [info loss: 1.480473]\n",
      "[Epoch 2/5] [Batch 220/938] [D loss: 0.228940] [G loss: 0.285742] [info loss: 1.505980]\n",
      "[Epoch 2/5] [Batch 240/938] [D loss: 0.215734] [G loss: 0.312311] [info loss: 1.494083]\n",
      "[Epoch 2/5] [Batch 260/938] [D loss: 0.207637] [G loss: 0.266464] [info loss: 1.491082]\n",
      "[Epoch 2/5] [Batch 280/938] [D loss: 0.228378] [G loss: 0.436767] [info loss: 1.477801]\n",
      "[Epoch 2/5] [Batch 300/938] [D loss: 0.266528] [G loss: 0.303881] [info loss: 1.483788]\n",
      "[Epoch 2/5] [Batch 320/938] [D loss: 0.223322] [G loss: 0.272647] [info loss: 1.494782]\n",
      "[Epoch 2/5] [Batch 340/938] [D loss: 0.269832] [G loss: 0.320501] [info loss: 1.476022]\n",
      "[Epoch 2/5] [Batch 360/938] [D loss: 0.220891] [G loss: 0.362705] [info loss: 1.492515]\n",
      "[Epoch 2/5] [Batch 380/938] [D loss: 0.212764] [G loss: 0.349221] [info loss: 1.502028]\n",
      "[Epoch 2/5] [Batch 400/938] [D loss: 0.246756] [G loss: 0.316630] [info loss: 1.480059]\n",
      "[Epoch 2/5] [Batch 420/938] [D loss: 0.220541] [G loss: 0.374189] [info loss: 1.489292]\n",
      "[Epoch 2/5] [Batch 440/938] [D loss: 0.250341] [G loss: 0.418048] [info loss: 1.477039]\n",
      "[Epoch 2/5] [Batch 460/938] [D loss: 0.218771] [G loss: 0.244211] [info loss: 1.473432]\n",
      "[Epoch 2/5] [Batch 480/938] [D loss: 0.235820] [G loss: 0.252592] [info loss: 1.486295]\n",
      "[Epoch 2/5] [Batch 500/938] [D loss: 0.258864] [G loss: 0.270162] [info loss: 1.474887]\n",
      "[Epoch 2/5] [Batch 520/938] [D loss: 0.224714] [G loss: 0.399950] [info loss: 1.480453]\n",
      "[Epoch 2/5] [Batch 540/938] [D loss: 0.252185] [G loss: 0.366808] [info loss: 1.478974]\n",
      "[Epoch 2/5] [Batch 560/938] [D loss: 0.226195] [G loss: 0.329559] [info loss: 1.495803]\n",
      "[Epoch 2/5] [Batch 580/938] [D loss: 0.228198] [G loss: 0.368607] [info loss: 1.493283]\n",
      "[Epoch 2/5] [Batch 600/938] [D loss: 0.211736] [G loss: 0.259543] [info loss: 1.479401]\n",
      "[Epoch 2/5] [Batch 620/938] [D loss: 0.200597] [G loss: 0.421596] [info loss: 1.475885]\n",
      "[Epoch 2/5] [Batch 640/938] [D loss: 0.233037] [G loss: 0.301952] [info loss: 1.472972]\n",
      "[Epoch 2/5] [Batch 660/938] [D loss: 0.228222] [G loss: 0.308376] [info loss: 1.498390]\n",
      "[Epoch 2/5] [Batch 680/938] [D loss: 0.207037] [G loss: 0.291151] [info loss: 1.510162]\n",
      "[Epoch 2/5] [Batch 700/938] [D loss: 0.203238] [G loss: 0.355987] [info loss: 1.489709]\n",
      "[Epoch 2/5] [Batch 720/938] [D loss: 0.193601] [G loss: 0.379716] [info loss: 1.477570]\n",
      "[Epoch 2/5] [Batch 740/938] [D loss: 0.234495] [G loss: 0.241042] [info loss: 1.495732]\n",
      "[Epoch 2/5] [Batch 760/938] [D loss: 0.213759] [G loss: 0.297362] [info loss: 1.483858]\n",
      "[Epoch 2/5] [Batch 780/938] [D loss: 0.230811] [G loss: 0.374810] [info loss: 1.487163]\n",
      "[Epoch 2/5] [Batch 800/938] [D loss: 0.234498] [G loss: 0.373272] [info loss: 1.478159]\n",
      "[Epoch 2/5] [Batch 820/938] [D loss: 0.179928] [G loss: 0.383344] [info loss: 1.489599]\n",
      "[Epoch 2/5] [Batch 840/938] [D loss: 0.193740] [G loss: 0.314370] [info loss: 1.473875]\n",
      "[Epoch 2/5] [Batch 860/938] [D loss: 0.208582] [G loss: 0.369972] [info loss: 1.482369]\n",
      "[Epoch 2/5] [Batch 880/938] [D loss: 0.200119] [G loss: 0.410354] [info loss: 1.472273]\n",
      "[Epoch 2/5] [Batch 900/938] [D loss: 0.193298] [G loss: 0.342779] [info loss: 1.484673]\n",
      "[Epoch 2/5] [Batch 920/938] [D loss: 0.219089] [G loss: 0.345020] [info loss: 1.480853]\n",
      "[Epoch 3/5] [Batch 0/938] [D loss: 0.199827] [G loss: 0.291005] [info loss: 1.477385]\n",
      "[Epoch 3/5] [Batch 20/938] [D loss: 0.230758] [G loss: 0.407993] [info loss: 1.475492]\n",
      "[Epoch 3/5] [Batch 40/938] [D loss: 0.211649] [G loss: 0.374591] [info loss: 1.498257]\n",
      "[Epoch 3/5] [Batch 60/938] [D loss: 0.189163] [G loss: 0.436744] [info loss: 1.502613]\n",
      "[Epoch 3/5] [Batch 80/938] [D loss: 0.219584] [G loss: 0.290728] [info loss: 1.475125]\n",
      "[Epoch 3/5] [Batch 100/938] [D loss: 0.223397] [G loss: 0.336275] [info loss: 1.486405]\n",
      "[Epoch 3/5] [Batch 120/938] [D loss: 0.219858] [G loss: 0.304665] [info loss: 1.490479]\n",
      "[Epoch 3/5] [Batch 140/938] [D loss: 0.197000] [G loss: 0.316147] [info loss: 1.484706]\n",
      "[Epoch 3/5] [Batch 160/938] [D loss: 0.215545] [G loss: 0.387044] [info loss: 1.483221]\n",
      "[Epoch 3/5] [Batch 180/938] [D loss: 0.216461] [G loss: 0.268353] [info loss: 1.476377]\n",
      "[Epoch 3/5] [Batch 200/938] [D loss: 0.213300] [G loss: 0.309489] [info loss: 1.501213]\n",
      "[Epoch 3/5] [Batch 220/938] [D loss: 0.218462] [G loss: 0.396180] [info loss: 1.509606]\n",
      "[Epoch 3/5] [Batch 240/938] [D loss: 0.204172] [G loss: 0.334266] [info loss: 1.493298]\n",
      "[Epoch 3/5] [Batch 260/938] [D loss: 0.210077] [G loss: 0.367670] [info loss: 1.501638]\n",
      "[Epoch 3/5] [Batch 280/938] [D loss: 0.195693] [G loss: 0.352095] [info loss: 1.492593]\n",
      "[Epoch 3/5] [Batch 300/938] [D loss: 0.218532] [G loss: 0.368023] [info loss: 1.476271]\n",
      "[Epoch 3/5] [Batch 320/938] [D loss: 0.215442] [G loss: 0.297715] [info loss: 1.497397]\n",
      "[Epoch 3/5] [Batch 340/938] [D loss: 0.183876] [G loss: 0.398007] [info loss: 1.479354]\n",
      "[Epoch 3/5] [Batch 360/938] [D loss: 0.174828] [G loss: 0.350612] [info loss: 1.473125]\n",
      "[Epoch 3/5] [Batch 380/938] [D loss: 0.202195] [G loss: 0.369380] [info loss: 1.480170]\n",
      "[Epoch 3/5] [Batch 400/938] [D loss: 0.242911] [G loss: 0.263969] [info loss: 1.488429]\n",
      "[Epoch 3/5] [Batch 420/938] [D loss: 0.207467] [G loss: 0.419022] [info loss: 1.479362]\n",
      "[Epoch 3/5] [Batch 440/938] [D loss: 0.205489] [G loss: 0.371372] [info loss: 1.510346]\n",
      "[Epoch 3/5] [Batch 460/938] [D loss: 0.192046] [G loss: 0.367013] [info loss: 1.499655]\n",
      "[Epoch 3/5] [Batch 480/938] [D loss: 0.202294] [G loss: 0.329913] [info loss: 1.477671]\n",
      "[Epoch 3/5] [Batch 500/938] [D loss: 0.200242] [G loss: 0.405387] [info loss: 1.475936]\n",
      "[Epoch 3/5] [Batch 520/938] [D loss: 0.215522] [G loss: 0.254314] [info loss: 1.502927]\n",
      "[Epoch 3/5] [Batch 540/938] [D loss: 0.215204] [G loss: 0.265958] [info loss: 1.473565]\n",
      "[Epoch 3/5] [Batch 560/938] [D loss: 0.191861] [G loss: 0.312505] [info loss: 1.486183]\n",
      "[Epoch 3/5] [Batch 580/938] [D loss: 0.196342] [G loss: 0.365071] [info loss: 1.495868]\n",
      "[Epoch 3/5] [Batch 600/938] [D loss: 0.224861] [G loss: 0.336198] [info loss: 1.473923]\n",
      "[Epoch 3/5] [Batch 620/938] [D loss: 0.204767] [G loss: 0.363302] [info loss: 1.494474]\n",
      "[Epoch 3/5] [Batch 640/938] [D loss: 0.215770] [G loss: 0.350245] [info loss: 1.491656]\n",
      "[Epoch 3/5] [Batch 660/938] [D loss: 0.219487] [G loss: 0.372353] [info loss: 1.483899]\n",
      "[Epoch 3/5] [Batch 680/938] [D loss: 0.224999] [G loss: 0.298566] [info loss: 1.487854]\n",
      "[Epoch 3/5] [Batch 700/938] [D loss: 0.197633] [G loss: 0.336622] [info loss: 1.473224]\n",
      "[Epoch 3/5] [Batch 720/938] [D loss: 0.239497] [G loss: 0.417037] [info loss: 1.516580]\n",
      "[Epoch 3/5] [Batch 740/938] [D loss: 0.260304] [G loss: 0.271002] [info loss: 1.477937]\n",
      "[Epoch 3/5] [Batch 760/938] [D loss: 0.220357] [G loss: 0.406994] [info loss: 1.492980]\n",
      "[Epoch 3/5] [Batch 780/938] [D loss: 0.218753] [G loss: 0.416586] [info loss: 1.480724]\n",
      "[Epoch 3/5] [Batch 800/938] [D loss: 0.191350] [G loss: 0.287080] [info loss: 1.496736]\n",
      "[Epoch 3/5] [Batch 820/938] [D loss: 0.227423] [G loss: 0.288514] [info loss: 1.480314]\n",
      "[Epoch 3/5] [Batch 840/938] [D loss: 0.254499] [G loss: 0.417528] [info loss: 1.491326]\n",
      "[Epoch 3/5] [Batch 860/938] [D loss: 0.238122] [G loss: 0.356622] [info loss: 1.483347]\n",
      "[Epoch 3/5] [Batch 880/938] [D loss: 0.230391] [G loss: 0.430124] [info loss: 1.482897]\n",
      "[Epoch 3/5] [Batch 900/938] [D loss: 0.224969] [G loss: 0.340111] [info loss: 1.503410]\n",
      "[Epoch 3/5] [Batch 920/938] [D loss: 0.222006] [G loss: 0.378953] [info loss: 1.493000]\n",
      "[Epoch 4/5] [Batch 0/938] [D loss: 0.209641] [G loss: 0.285551] [info loss: 1.481190]\n",
      "[Epoch 4/5] [Batch 20/938] [D loss: 0.210197] [G loss: 0.309960] [info loss: 1.498743]\n",
      "[Epoch 4/5] [Batch 40/938] [D loss: 0.221210] [G loss: 0.322482] [info loss: 1.483770]\n",
      "[Epoch 4/5] [Batch 60/938] [D loss: 0.246935] [G loss: 0.394648] [info loss: 1.484532]\n",
      "[Epoch 4/5] [Batch 80/938] [D loss: 0.219925] [G loss: 0.365281] [info loss: 1.491549]\n",
      "[Epoch 4/5] [Batch 100/938] [D loss: 0.257538] [G loss: 0.284987] [info loss: 1.489454]\n",
      "[Epoch 4/5] [Batch 120/938] [D loss: 0.204450] [G loss: 0.294355] [info loss: 1.493837]\n",
      "[Epoch 4/5] [Batch 140/938] [D loss: 0.224912] [G loss: 0.271445] [info loss: 1.473300]\n",
      "[Epoch 4/5] [Batch 160/938] [D loss: 0.234943] [G loss: 0.370829] [info loss: 1.486292]\n",
      "[Epoch 4/5] [Batch 180/938] [D loss: 0.175314] [G loss: 0.350603] [info loss: 1.500500]\n",
      "[Epoch 4/5] [Batch 200/938] [D loss: 0.190670] [G loss: 0.293240] [info loss: 1.474337]\n",
      "[Epoch 4/5] [Batch 220/938] [D loss: 0.218832] [G loss: 0.340798] [info loss: 1.487641]\n",
      "[Epoch 4/5] [Batch 240/938] [D loss: 0.214143] [G loss: 0.296416] [info loss: 1.477606]\n",
      "[Epoch 4/5] [Batch 260/938] [D loss: 0.219642] [G loss: 0.368517] [info loss: 1.479012]\n",
      "[Epoch 4/5] [Batch 280/938] [D loss: 0.214371] [G loss: 0.353087] [info loss: 1.495614]\n",
      "[Epoch 4/5] [Batch 300/938] [D loss: 0.194273] [G loss: 0.312231] [info loss: 1.477731]\n",
      "[Epoch 4/5] [Batch 320/938] [D loss: 0.220648] [G loss: 0.372461] [info loss: 1.488256]\n",
      "[Epoch 4/5] [Batch 340/938] [D loss: 0.197578] [G loss: 0.234345] [info loss: 1.492132]\n",
      "[Epoch 4/5] [Batch 360/938] [D loss: 0.225855] [G loss: 0.293846] [info loss: 1.477913]\n",
      "[Epoch 4/5] [Batch 380/938] [D loss: 0.257976] [G loss: 0.317894] [info loss: 1.504077]\n",
      "[Epoch 4/5] [Batch 400/938] [D loss: 0.225391] [G loss: 0.328102] [info loss: 1.498336]\n",
      "[Epoch 4/5] [Batch 420/938] [D loss: 0.183232] [G loss: 0.395984] [info loss: 1.476408]\n",
      "[Epoch 4/5] [Batch 440/938] [D loss: 0.199062] [G loss: 0.286897] [info loss: 1.485970]\n",
      "[Epoch 4/5] [Batch 460/938] [D loss: 0.207559] [G loss: 0.323370] [info loss: 1.493012]\n",
      "[Epoch 4/5] [Batch 480/938] [D loss: 0.204349] [G loss: 0.323974] [info loss: 1.499109]\n",
      "[Epoch 4/5] [Batch 500/938] [D loss: 0.187950] [G loss: 0.290110] [info loss: 1.493982]\n",
      "[Epoch 4/5] [Batch 520/938] [D loss: 0.190930] [G loss: 0.455357] [info loss: 1.496912]\n",
      "[Epoch 4/5] [Batch 540/938] [D loss: 0.197581] [G loss: 0.344931] [info loss: 1.492367]\n",
      "[Epoch 4/5] [Batch 560/938] [D loss: 0.230633] [G loss: 0.294691] [info loss: 1.478511]\n",
      "[Epoch 4/5] [Batch 580/938] [D loss: 0.230873] [G loss: 0.394694] [info loss: 1.481050]\n",
      "[Epoch 4/5] [Batch 600/938] [D loss: 0.193146] [G loss: 0.355289] [info loss: 1.480398]\n",
      "[Epoch 4/5] [Batch 620/938] [D loss: 0.193309] [G loss: 0.272997] [info loss: 1.473855]\n",
      "[Epoch 4/5] [Batch 640/938] [D loss: 0.186963] [G loss: 0.388158] [info loss: 1.480694]\n",
      "[Epoch 4/5] [Batch 660/938] [D loss: 0.216013] [G loss: 0.278367] [info loss: 1.482216]\n",
      "[Epoch 4/5] [Batch 680/938] [D loss: 0.213659] [G loss: 0.338895] [info loss: 1.487166]\n",
      "[Epoch 4/5] [Batch 700/938] [D loss: 0.206077] [G loss: 0.401465] [info loss: 1.485662]\n",
      "[Epoch 4/5] [Batch 720/938] [D loss: 0.184531] [G loss: 0.327660] [info loss: 1.473249]\n",
      "[Epoch 4/5] [Batch 740/938] [D loss: 0.201888] [G loss: 0.493573] [info loss: 1.484655]\n",
      "[Epoch 4/5] [Batch 760/938] [D loss: 0.231237] [G loss: 0.345895] [info loss: 1.500286]\n",
      "[Epoch 4/5] [Batch 780/938] [D loss: 0.234345] [G loss: 0.308732] [info loss: 1.486444]\n",
      "[Epoch 4/5] [Batch 800/938] [D loss: 0.253060] [G loss: 0.262522] [info loss: 1.481828]\n",
      "[Epoch 4/5] [Batch 820/938] [D loss: 0.208748] [G loss: 0.316929] [info loss: 1.476802]\n",
      "[Epoch 4/5] [Batch 840/938] [D loss: 0.190010] [G loss: 0.331998] [info loss: 1.475549]\n",
      "[Epoch 4/5] [Batch 860/938] [D loss: 0.260379] [G loss: 0.406350] [info loss: 1.475540]\n",
      "[Epoch 4/5] [Batch 880/938] [D loss: 0.215250] [G loss: 0.326988] [info loss: 1.474205]\n",
      "[Epoch 4/5] [Batch 900/938] [D loss: 0.203915] [G loss: 0.283993] [info loss: 1.475954]\n",
      "[Epoch 4/5] [Batch 920/938] [D loss: 0.201693] [G loss: 0.339224] [info loss: 1.502843]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(opt.n_epochs):\n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "        batch_size = imgs.shape[0]\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad = False)\n",
    "        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad = False)\n",
    "        \n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(FloatTensor))\n",
    "        labels = to_categorical(labels.numpy(), num_columns = opt.n_classes)\n",
    "        \n",
    "        ###################\n",
    "        # Train Generator #\n",
    "        ###################\n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        # Sample noise and labels as generator input\n",
    "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))\n",
    "        label_input = to_categorical(np.random.randint(0, opt.n_classes, batch_size), num_columns = opt.n_classes)\n",
    "        code_input = Variable(FloatTensor(np.random.uniform(-1, 1, (batch_size, opt.code_dim))))\n",
    "        \n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z, label_input, code_input)\n",
    "        \n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        validity, _, _ = discriminator(gen_imgs)\n",
    "        g_loss = adversarial_loss(validity, valid)\n",
    "        \n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        \n",
    "        #######################\n",
    "        # Train Discriminator #\n",
    "        #######################\n",
    "        \n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        # Loss for real images\n",
    "        real_pred, _, _ = discriminator(real_imgs)\n",
    "        d_real_loss = adversarial_loss(real_pred, valid)\n",
    "        \n",
    "        # Loss for fake images\n",
    "        fake_pred, _, _ = discriminator(gen_imgs.detach())\n",
    "        d_fake_loss = adversarial_loss(fake_pred, fake)\n",
    "        \n",
    "        # Total discriminator loss\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "        \n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        \n",
    "        ####################\n",
    "        # Information Loss #\n",
    "        ####################\n",
    "        \n",
    "        optimizer_info.zero_grad()\n",
    "        \n",
    "        # Sample labels\n",
    "        sampled_labels = np.random.randint(0, opt.n_classes, batch_size)\n",
    "        \n",
    "        # Ground truth labels\n",
    "        gt_labels = Variable(LongTensor(sampled_labels), requires_grad = False)\n",
    "        \n",
    "        # Sample noise, labels and code as generator input\n",
    "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))\n",
    "        label_input = to_categorical(sampled_labels, num_columns = opt.n_classes)\n",
    "        code_input = Variable(FloatTensor(np.random.uniform(-1, 1, (batch_size, opt.code_dim))))\n",
    "        \n",
    "        gen_imgs = generator(z, label_input, code_input)\n",
    "        _, pred_label, pred_code = discriminator(gen_imgs)\n",
    "        \n",
    "        info_loss = lambda_cat * categorical_loss(pred_label, gt_labels) + lambda_con * continuous_loss(pred_code, code_input)\n",
    "            \n",
    "        info_loss.backward()\n",
    "        optimizer_info.step()\n",
    "        \n",
    "        ################\n",
    "        # Log Progress #\n",
    "        ################\n",
    "        \n",
    "        if i % 20 == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] [info loss: %f]\"\n",
    "                % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item(), info_loss.item())\n",
    "            )\n",
    "            \n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % opt.sample_interval == 0:\n",
    "            sample_image(n_row=10, batches_done=batches_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-chicken",
   "metadata": {
    "papermill": {
     "duration": 0.102349,
     "end_time": "2021-04-26T14:20:18.074519",
     "exception": false,
     "start_time": "2021-04-26T14:20:17.972170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-island",
   "metadata": {
    "papermill": {
     "duration": 0.09306,
     "end_time": "2021-04-26T14:20:18.261498",
     "exception": false,
     "start_time": "2021-04-26T14:20:18.168438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-deficit",
   "metadata": {
    "papermill": {
     "duration": 0.09329,
     "end_time": "2021-04-26T14:20:18.452033",
     "exception": false,
     "start_time": "2021-04-26T14:20:18.358743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 272.752459,
   "end_time": "2021-04-26T14:20:20.795376",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-26T14:15:48.042917",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
