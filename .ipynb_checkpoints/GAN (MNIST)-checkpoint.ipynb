{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. GAN\n",
    "- reference : https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/gan/gan.py\n",
    "- paper : https://arxiv.org/abs/1406.2661"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse -> jupyter notebook X\n",
    "import easydict\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make images folder\n",
    "os.makedirs('images', exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Parameter Setting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# jupyter notebook에서는 사용 X\n",
    "# easydict 라이브러리를 사용하여 대체\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n_epochs\", type = int, default = 200, help = \"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type = int, default = 64, help = \"size of the batchs\")\n",
    "parser.add_argument(\"--lr\", type = float, default = 0.0002, help = \"adam: learning rate\")\n",
    "parser.add_argument(\"--b1\", type = float, default = 0.5, help = \"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--b2\", type = float, default = 0.99, help = \"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--n_cpu\", type = int, default = 8, help = \"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--latent_dim\", type = int, default = 100, help = \"dimensionality of the latent space\")\n",
    "parser.add_argument(\"--img_size\", type = int, default = 28, help = \"size of each image dimention\")\n",
    "parser.add_argument(\"--channels\", type = int, default = 1, help = \"number of image channels\")\n",
    "parser.add_argument(\"--sample_interval\", type = int, default = 400, help = \"interval between image samples\")\n",
    "opt = parser.parse_args()\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = easydict.EasyDict({\"n_epochs\" : 200,\n",
    "                         \"batch_size\" : 64,\n",
    "                         \"lr\" : 0.0002,\n",
    "                         \"b1\" : 0.5,\n",
    "                         \"b2\" : 0.99,\n",
    "                         \"n_cpu\" : 8,\n",
    "                         \"latent_dim\" : 100,\n",
    "                         \"img_size\" : 28,\n",
    "                         \"channels\" : 1,\n",
    "                         \"sample_interval\" : 400})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_epochs': 200, 'batch_size': 64, 'lr': 0.0002, 'b1': 0.5, 'b2': 0.99, 'n_cpu': 8, 'latent_dim': 100, 'img_size': 28, 'channels': 1, 'sample_interval': 400}\n"
     ]
    }
   ],
   "source": [
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (opt.channels, opt.img_size, opt.img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        def block(in_feat, out_feat, normalize = True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace = True))\n",
    "            return layers\n",
    "        \n",
    "        self.model = nn.Sequential(*block(opt.latent_dim, 128, normalize = False),\n",
    "                                   *block(128, 256),\n",
    "                                   *block(256, 512),\n",
    "                                   *block(512, 1024),\n",
    "                                   nn.Linear(1024, int(np.prod(img_shape))),\n",
    "                                   nn.Tanh()\n",
    "                                  )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *img_shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(nn.Linear(int(np.prod(img_shape)), 512),\n",
    "                                   nn.LeakyReLU(0.2, inplace = True),\n",
    "                                   nn.Linear(512, 256),\n",
    "                                   nn.LeakyReLU(0.2, inplace = True),\n",
    "                                   nn.Linear(256, 1),\n",
    "                                   nn.Sigmoid()\n",
    "                                  )\n",
    "        \n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_loss = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "os.makedirs(\"../data/mnist\", exist_ok = True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(\n",
    "                \"../data/mnist\",\n",
    "                train = True,\n",
    "                download = True,\n",
    "                transform = transforms.Compose(\n",
    "                    [transforms.Resize(opt.img_size), transforms.ToTensor(),\n",
    "                     transforms.Normalize([0.5], [0.5])]\n",
    "                )\n",
    "            ),\n",
    "            batch_size = opt.batch_size,\n",
    "            shuggle = True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
